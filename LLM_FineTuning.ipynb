{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77ed059fa8bc4f3bbbcd46800deedfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ab3164455464ca993629f412018f675",
              "IPY_MODEL_93b7e73eca514ee7b279ebf3138637fc",
              "IPY_MODEL_463d393e948b470ba4d8752c5a01170a"
            ],
            "layout": "IPY_MODEL_94207f7222df4dc48726f9519c61cbf1"
          }
        },
        "2ab3164455464ca993629f412018f675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d31904c9be6e4979a24b29ffb7f1b40d",
            "placeholder": "​",
            "style": "IPY_MODEL_ce9df17aa51147999356fdbc0a562806",
            "value": "100%"
          }
        },
        "93b7e73eca514ee7b279ebf3138637fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3ffee202334180a7f3b348b151bd58",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f910b19e3b77490abd3c3b29dc2ba8f5",
            "value": 30
          }
        },
        "463d393e948b470ba4d8752c5a01170a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ca6998cf244efeb57fc0d495ae31e0",
            "placeholder": "​",
            "style": "IPY_MODEL_f91f440b4a68445197baac86c3b42fa3",
            "value": " 30/30 [10:13&lt;00:00, 25.59s/it]"
          }
        },
        "94207f7222df4dc48726f9519c61cbf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31904c9be6e4979a24b29ffb7f1b40d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9df17aa51147999356fdbc0a562806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3ffee202334180a7f3b348b151bd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f910b19e3b77490abd3c3b29dc2ba8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5ca6998cf244efeb57fc0d495ae31e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91f440b4a68445197baac86c3b42fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shrouk-Adel/Fine_Tuning_Qwen2.5_LLaMA_Factory/blob/main/LLM_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7N01LSgpIDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbf256e-e9c3-480e-8326-263587090103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "OJu7CozttUM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU transformers==4.48.3 datasets==3.2.0 optimum==1.24.0\n",
        "!pip install -qU openai==1.61.0 wandb\n",
        "!pip install json-repair\n",
        "!pip install -qU faker==35.2.0\n",
        "!pip install -qU vllm==0.7.2"
      ],
      "metadata": {
        "id": "G0MDnCMEqPRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca25e7a5-1266-45da-a6fb-a57b75cb3a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: json-repair in /usr/local/lib/python3.11/dist-packages (0.45.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "!cd LLaMA-Factory & pip install -e \".[torch,metrics]\""
      ],
      "metadata": {
        "id": "Hsn5SUVspd3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "\n",
        "# Get the wandb API key from userdata\n",
        "wandb_api_key = userdata.get('wandb')\n",
        "\n",
        "# Pass the API key to the `key` parameter\n",
        "wandb.login(key=wandb_api_key)\n",
        "\n",
        "Hf_token = userdata.get('HF_Token')\n",
        "!huggingface-cli login --token {Hf_token}"
      ],
      "metadata": {
        "id": "0QWdEWaZrh4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_9UsUqKwvU0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import requests\n",
        "\n",
        "from pydantic import BaseModel,Field\n",
        "from typing import List,Literal,Optional\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "import json_repair\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "data_dir ='/gdrive/MyDrive/Fine-Tuning'\n",
        "base_model_Id ='Qwen/Qwen2.5-1.5B-Instruct'\n",
        "\n",
        "device='cuda'\n",
        "torch_dtype=None\n",
        "\n",
        "\n",
        "def parse_json(text):\n",
        "  try:\n",
        "    return json_repair.loads(text)\n",
        "  except:\n",
        "    return None"
      ],
      "metadata": {
        "id": "7REHFhjkuUHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks"
      ],
      "metadata": {
        "id": "QBlEklQj5UBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"\n",
        "ذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\n",
        " حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\n",
        "\n",
        "التقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\n",
        "الرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\n",
        " تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\n",
        "\n",
        " الأبعاد الثلاثة للعلاقة بالمال\n",
        "بحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\n",
        "\n",
        "الاكتساب (A): يميل الأفراد الذين ينتمون لهذا\n",
        " البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\n",
        "في تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\n",
        " النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\n",
        " أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\n",
        "\n",
        "الاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\n",
        "المتعة والراحة. ومع ذلك، قد يصبح\n",
        "البعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\n",
        "\n",
        "الإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\n",
        " قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\n",
        "\n",
        " كيف تؤثر العائلة على علاقتنا بالمال؟\n",
        "يشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\n",
        " \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\n",
        "كمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\n",
        "\n",
        "لتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\n",
        "(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\n",
        "وهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\n",
        "\n",
        "تتضمن هذه الأداة:\n",
        "\n",
        "رسم شجرة عائلية.\n",
        "تصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\n",
        "تحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\n",
        "على سبيل المثال، إذا نشأ شخص في عائلة\n",
        "اعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\n",
        " أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UCwR1gl_whJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details Extraction"
      ],
      "metadata": {
        "id": "A52Coqkr6YSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build schema for sturctured output\n",
        "# {\n",
        "#     'stroy_title':' ',\n",
        "#     'story_keywords':['kw1','kw2',....],\n",
        "#     'story_summary':[' ',,,,,,,' '],\n",
        "#     'story_category':[]\n",
        "#     'story_entity':{\n",
        "#            'entity_value':'القاهرة',\n",
        "#            'entity_type':'place'\n",
        "#             }\n",
        "# }\n",
        "\n",
        "Entity_type = Literal['person-male','person-female','place','money','product','location','envent','time','law','quantity'\n",
        "                       'artifact','organization','disease']\n",
        "\n",
        "Categories =Literal['Politics','Arts','Health','Technology','Sports','Economy','Science','Entertainment','not-specified']\n",
        "\n",
        "class Entity(BaseModel):\n",
        "  entity_value:str =Field(...,Description='the actual name or value of the entity')\n",
        "  entity_type:Entity_type =Field(...,Description='Type of recognized entity')\n",
        "\n",
        "class NewsDetails(BaseModel):\n",
        "  story_title:str =Field(...,min_length=5,max_length=300,\n",
        "                         Description='A fully informative and SEO Optimize title for the story')\n",
        "\n",
        "  story_keywords :List[str] =Field(...,min_items=1,Description ='Relevant keywords related to story')\n",
        "\n",
        "  story_summary :List[str] =Field(...,min_items=1,max_items = 5,Description ='summarized key points about story points (1-5)')\n",
        "\n",
        "  story_category :Categories =Field(..., Description ='Category of the news story')\n",
        "\n",
        "  story_entity:List[Entity]=Field(...,min_items=1 , max_items=10 , Description ='List of identified entities in the story')\n",
        "\n"
      ],
      "metadata": {
        "id": "m9GXGvY66W85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Details_extraction_messages=[\n",
        "    {\n",
        "        'role':'system',\n",
        "        'content':'\\n'.join([\n",
        "            'you are NLP data parser',\n",
        "            'generate the output in the same story language',\n",
        "            'Extract details as mentioned as text',\n",
        "            'Do not generate any introduction or conclusion',\n",
        "            'you have to extract json details from text according to the pydantic details',\n",
        "        ])\n",
        "    },{\n",
        "        'role':'user',\n",
        "        'content':'\\n'.join([\n",
        "            '## Story:',\n",
        "            story.strip(),\n",
        "            '',\n",
        "\n",
        "            'the pydantic details:',\n",
        "            json.dumps(\n",
        "                NewsDetails.model_json_schema(),ensure_ascii=False\n",
        "                )\n",
        "        ])\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "v_xk6i_9qF2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "UF1gXH_z4o1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_Id,\n",
        "    device_map='auto',\n",
        "    torch_dtype=torch_dtype\n",
        "\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")"
      ],
      "metadata": {
        "id": "Si0IMjNMydxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(message):\n",
        "  text = tokenizer.apply_chat_template(\n",
        "      message,\n",
        "      tokenize=False,\n",
        "      add_generation_prompt=True\n",
        "  )\n",
        "\n",
        "  model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "  generated_ids = model.generate(\n",
        "      **model_inputs,\n",
        "      max_new_tokens=512\n",
        "  )\n",
        "  generated_ids = [\n",
        "      output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "  ]\n",
        "\n",
        "  response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "  return response\n",
        "\n",
        "response =generate_response(Details_extraction_messages)"
      ],
      "metadata": {
        "id": "FcZ5mAvV0QfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgCfrRQe5AOF",
        "outputId": "d117f2b4-fa9f-45ad-f60d-c5c95ab6fe16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"story_title\": \"The Role of Family in Financial Relationships\",\n",
            "  \"story_keywords\": [\n",
            "    \"financial relationships\",\n",
            "    \"family influence\",\n",
            "    \"moneymaking\",\n",
            "    \"wealth management\",\n",
            "    \"child development\"\n",
            "  ],\n",
            "  \"story_summary\": [\n",
            "    \"Forbes reported that family plays a crucial role in shaping individuals' financial relationships.\",\n",
            "    \"The relationship between individuals and money is influenced by inherited behavioral patterns across generations.\"\n",
            "  ],\n",
            "  \"story_category\": \"Economy\",\n",
            "  \"story_entity\": [\n",
            "    {\n",
            "      \"$ref\": \"#/$defs/Entity\",\n",
            "      \"entity_value\": \"Forbes\",\n",
            "      \"entity_type\": \"Organization\"\n",
            "    },\n",
            "    {\n",
            "      \"$ref\": \"#/$defs/Entity\",\n",
            "      \"entity_value\": \"Shain Entine\",\n",
            "      \"entity_type\": \"Person-Female\"\n",
            "    },\n",
            "    {\n",
            "      \"$ref\": \"#/$defs/Entity\",\n",
            "      \"entity_value\": \"Financial Therapy Association\",\n",
            "      \"entity_type\": \"Organization\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation"
      ],
      "metadata": {
        "id": "0GgWtqNn6gYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# {\n",
        "#     'translation_title':' ',\n",
        "#     'translation_content':''\n",
        "# }\n",
        "\n",
        "class TranslatedStory(BaseModel):\n",
        "  translation_titl:str =Field(...,min_length =5,Description ='genrate title for the translated story')\n",
        "  translation_content:str =Field(...,min_lenght =5,Desciption ='Tranlated Content for the new Story ')\n",
        "\n",
        "\n",
        "target_language='English'\n",
        "translation_messages=[\n",
        "    {\n",
        "\n",
        "        'role':'system',\n",
        "        'content':'\\n'.join([\n",
        "            'you are a professional translator',\n",
        "            'translate story for the target language',\n",
        "            'do not generate any introduction or conclusion',\n",
        "            'follow the provided schema to generate json'\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        'role':'user',\n",
        "        'content':'\\n'.join([\n",
        "            '## Story:',\n",
        "            story.strip(),\n",
        "            '',\n",
        "\n",
        "            'the pydantic details:',\n",
        "            json.dumps(\n",
        "                TranslatedStory.model_json_schema(),ensure_ascii=False\n",
        "                ),\n",
        "            '',\n",
        "\n",
        "            'Target language:',\n",
        "             target_language,\n",
        "        ])\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "YIfNF0_J5IuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response =generate_response(translation_messages)"
      ],
      "metadata": {
        "id": "Wxulh3Yt9-PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drTMYAJt-hq0",
        "outputId": "87978ef9-6ac1-466e-8cc8-1690b3e6a94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"translation_titl\": \"Family Influence on Financial Relationships\",\n",
            "  \"translation_content\": \"Forbes magazine reported that the family plays a crucial role in shaping individuals' relationships with money, influenced by inherited financial behaviors across generations.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_repair.loads(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI4GO3C9ZsXl",
        "outputId": "b7a2d410-11be-4e40-c990-6714b7c9c4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation_titl': 'Family Influence on Financial Relationships',\n",
              " 'translation_content': \"Forbes magazine reported that the family plays a crucial role in shaping individuals' relationships with money, influenced by inherited financial behaviors across generations.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation DeepSeek-r1"
      ],
      "metadata": {
        "id": "UtH63PKwrtah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "OpenRouter_api_key =userdata.get('open_router').strip()\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=OpenRouter_api_key,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "\n",
        "  model=\"deepseek/deepseek-r1:free\",\n",
        "  messages= Details_extraction_messages,\n",
        "  temperature=0.2,\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYsPNGTEryx2",
        "outputId": "28f0ceca-fb8f-4f96-ce1c-c866492c0f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"story_title\": \"دور العائلة في تشكيل العلاقة بالمال: الأبعاد الثلاثة وتأثيرها على الشخصية المالية\",\n",
            "  \"story_keywords\": [\n",
            "    \"العائلة\",\n",
            "    \"الشخصية المالية\",\n",
            "    \"فوربس\",\n",
            "    \"الأبعاد المالية\",\n",
            "    \"رابطة العلاج المالي\",\n",
            "    \"مخطط الجينوم المالي\"\n",
            "  ],\n",
            "  \"story_summary\": [\n",
            "    \"تأثير العائلة على أنماط السلوك المالي عبر الأجيال وفقًا لدراسات شاين إنيت\",\n",
            "    \"ثلاثة أبعاد للعلاقة بالمال: الاكتساب (A)، الاستخدام (U)، الإدارة (M)\",\n",
            "    \"ارتباط السلوك المالي بتجارب الطفولة مثل استخدام المال كمكافأة أو الإنفاق المفرط\",\n",
            "    \"دور أداة مخطط الجينوم المالي في تحليل الأنماط المالية العائلية\",\n",
            "    \"إمكانية تحوّل الأنماط المالية إلى سلوكيات غير صحية كالهوس بالثروة أو التقشف المفرط\"\n",
            "  ],\n",
            "  \"story_category\": \"Economy\",\n",
            "  \"story_entity\": [\n",
            "    {\n",
            "      \"entity_value\": \"فوربس\",\n",
            "      \"entity_type\": \"organization\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"شاين إنيت\",\n",
            "      \"entity_type\": \"person-male\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"رابطة العلاج المالي\",\n",
            "      \"entity_type\": \"organization\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"مخطط الجينوم المالي\",\n",
            "      \"entity_type\": \"quantityartifact\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion_t = client.chat.completions.create(\n",
        "\n",
        "  model=\"deepseek/deepseek-r1:free\",\n",
        "  messages= translation_messages,\n",
        "  temperature=0.2,\n",
        ")\n",
        "print(completion_t.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAdeWhYrxoge",
        "outputId": "b02419b0-a169-4a26-fa95-f6896ed31bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"translation_titl\": \"Forbes Reports: How Family Shapes Our Financial Relationships and Behaviors\",\n",
            "  \"translation_content\": \"Forbes magazine highlighted the pivotal role families play in shaping individuals’ relationships with money, noting that these relationships are influenced by financial behavior patterns inherited across generations.\\n\\nThe report, based on research by Professor Shane Enitt on financial well-being, explains that everyone has a \\\"financial personality\\\" determined by their interaction with money. This personality is directly influenced by family upbringing and childhood experiences.\\n\\n**The Three Dimensions of Financial Relationships**\\nAccording to the study, three key dimensions shape our relationship with money:\\n\\n1. **Acquisition (A):** Individuals in this category view money as a collectible commodity, seeing wealth accumulation as an end goal. The downside includes risks of developing an obsession with wealth or, conversely, outright rejection of money as a corrupting force.\\n\\n2. **Use (U):** These individuals see money as a tool for enjoying life, valuing it for its ability to provide comfort and pleasure. However, some may develop spending addictions, while others adopt extreme frugality due to fear of the future.\\n\\n3. **Management (M):** This group views money as a responsibility requiring careful planning. In extreme cases, it can lead to obsessive budgeting, negatively impacting personal relationships.\\n\\n**How Family Influences Financial Behavior**\\nThe report emphasizes that family experiences play a key role in defining an individual’s financial personality. For example, if a parent uses money as a reward for good behavior, the child may adopt similar patterns in adulthood.\\n\\nTo analyze these influences, the Financial Therapy Association developed the *Money Genogram* tool, which maps financial patterns within families. The tool includes:\\n\\n- A family tree diagram.\\n- Categorizing family members based on the three financial dimensions (A, U, M).\\n- Labeling each individual’s financial behavior as healthy (+) or unhealthy (-).\\n\\nFor instance, someone raised in a family with a history of overspending may either adopt the same habits or react by becoming excessively frugal as a psychological response.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=completion.choices[0].message.content\n",
        "type(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa5f5tknZnOB",
        "outputId": "d626bb00-a18a-4a67-b35e-2093febf7fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_repair.loads(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA-67u1jmOBx",
        "outputId": "97338a04-7307-4b25-abbb-5d578721df63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'story_title': 'دور العائلة في تشكيل العلاقة بالمال: الأبعاد الثلاثة وتأثيرها على الشخصية المالية',\n",
              " 'story_keywords': ['العائلة',\n",
              "  'الشخصية المالية',\n",
              "  'فوربس',\n",
              "  'الأبعاد المالية',\n",
              "  'رابطة العلاج المالي',\n",
              "  'مخطط الجينوم المالي'],\n",
              " 'story_summary': ['تأثير العائلة على أنماط السلوك المالي عبر الأجيال وفقًا لدراسات شاين إنيت',\n",
              "  'ثلاثة أبعاد للعلاقة بالمال: الاكتساب (A)، الاستخدام (U)، الإدارة (M)',\n",
              "  'ارتباط السلوك المالي بتجارب الطفولة مثل استخدام المال كمكافأة أو الإنفاق المفرط',\n",
              "  'دور أداة مخطط الجينوم المالي في تحليل الأنماط المالية العائلية',\n",
              "  'إمكانية تحوّل الأنماط المالية إلى سلوكيات غير صحية كالهوس بالثروة أو التقشف المفرط'],\n",
              " 'story_category': 'Economy',\n",
              " 'story_entity': [{'entity_value': 'فوربس', 'entity_type': 'organization'},\n",
              "  {'entity_value': 'شاين إنيت', 'entity_type': 'person-male'},\n",
              "  {'entity_value': 'رابطة العلاج المالي', 'entity_type': 'organization'},\n",
              "  {'entity_value': 'مخطط الجينوم المالي', 'entity_type': 'quantityartifact'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### knowledge Distillation"
      ],
      "metadata": {
        "id": "aNCGnEmLdNp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_paths =join(data_dir,'Datasets','news-sample.jsonl')\n",
        "\n",
        "raw_data =[]\n",
        "for line in open(raw_data_paths):\n",
        "  if line.strip()=='':\n",
        "    continue\n",
        "\n",
        "  raw_data.append(json.loads(line.strip()))\n",
        "\n",
        "# shuffle data\n",
        "random.Random(101).shuffle(raw_data)\n",
        "print(f'Raw Data: {len(raw_data)}')"
      ],
      "metadata": {
        "id": "Va0q-O0i-jmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdaea9df-44ef-4108-cb98-d123e959eaa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Data: 2400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TgE6Faymt21d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_data[0]['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVxTFFSwnkAn",
        "outputId": "4c8ebe41-8772-4520-f186-2b502e3a1edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "يواصل المعهد العربي في باريس استقبال زواره في معرض ما تقدمه فلسطين للعالم لإطلاعهم على الإرث الثقافي والفني للفلسطينيين؛ من خلال أعمال فنية لآمالهم وصور لواقعهم الأليم تحت الاحتلال. \n",
            " ويرى رئيس المعهد جاك لانغ -الذي أُعيد انتخابه قبل أيام للدورة الرابعة- ما يحدث في غزة حاليا جراء العدوان الإسرائيلي أنه كارثة. \n",
            " والمعهد هو مركز ثقافي وواجهة دبلوماسية يديرها لانغ منذ 2013 ويقع على ضفة نهر السين في باريس. \n",
            " وأشار لانغ، الذي شغل سابقا منصب وزير الثقافة بفرنسا، إلى أن المعرض هو إهداء للشعب الفلسطيني، ومُدّد ليستقبل مزيدا من الزوار حتى 31 ديسمبركانون الأول الجاري. \n",
            " ويضم المعرض، الذي افتُتح أواخر مايوأيار الماضي، حسب لانغ العديد من المعارض الفرعية عن فلسطين وعن غزة بالتحديد، من بينها معرض الصور اليومية عن الحياة في غزة. \n",
            " كما يشتمل على معرض الصور الفوتوكرومية القائم على تلوين صور من فلسطين تعود للقرن الـ19. \n",
            " ويعرض الفنان الفلسطيني محمد أبو سل عملا فريدا بعنوان مترو غزة، وهو عبارة عن عمل تركيبي متعدد الوسائط، لاقى إعجابا من الزوار. \n",
            " ويحضر الشاعر الفلسطيني الراحل محمود درويش من خلال أشعاره في أروقة المعرض، إلى جانب الكاتب والشاعر الفرنسي الملقب بعاشق فلسطين جان جينيه. \n",
            " ومن الأعمال التي لاقت إعجاب الزوار عمل فني بعنوان بيوت غزة 2008-2009 عرضت فيه صور منازل في القطاع تدمرت بفعل القصف الإسرائيلي على غزة في 2008 و2009. \n",
            " وقال لانغ لوكالة الأناضول أريد من المعرض أن يظهر الغنى الثقافي والإبداع لدى الشعب الفلسطيني من جميع النواحي. \n",
            " وأشار إلى أن اسم الشعب الفلسطيني اقترن بالحرب ومن النادر أن يُسلط الضوء على ثقافته وفنه. \n",
            " ويضم المعرض -أيضا- المتحف الفلسطيني في المنفى وأسس بالتعاون مع المؤرخ، سفير فلسطين الأسبق لدى اليونسكو إلياس صنبر. \n",
            " ويضم تحفا تُبرع بها للمتحف لمدة 5 سنوات بإشراف المعهد العربي، وقال لانغ تعليقا على هذا المتحف نأمل أن نتمكن يوما ما من عرض هذا المتحف في القدس. \n",
            " وبيّن لانغ أن المعرض حظي باهتمام كبير من الفرنسيين لا سيما الشباب، قائلا أريد التعريف أكثر بفلسطين، ثمة كثير من المعلومات المغلوطة حيال القضية الفلسطينية. \n",
            " وأضاف رئيس المعهد العربي دُمّر العديد من المنازل والأحياء في غزة المعروضة صورها في المعرض. \n",
            " وختم بالقول أعتقد أن وجود هذه الصور والأعمال هنا أمر جيد من أجل إبقاء الأمل لدى فناني غزة. \n",
            " وكان المعهد قد أصدر كتابا جماعيا قبل شهور قليلة بعنوان ما تقدمه فلسطين للعالم، وصدر باللغة الفرنسية ضمن السلسلة الدورية عربوراما بالاشتراك مع دار النشر الفرنسية سوي Seuil. \n",
            " ضم الكتاب مجموعة من المقالات الصحفية والدراسات الفكرية والبحوث الاجتماعية والقصائد الشعرية والصور والخرائط التوضيحية والرسومات الفنية واللوحات التشكيلية، لنخبة متميزة من الصحفيين والمفكرين والكتاب والشعراء والفنانين والرسامين والمؤرخين والباحثين العرب والأوروبيين، التي تتغنى كلها بحب سيدة الأرض فلسطين، وتحاول أن ترسم لها بالحرف والريشة صورة تتراوح بين الحلم والواقع. \n",
            " والكتاب القيّم أسهم فيه 50 مبدعا على غرار المثقف والكاتب إلياس صنبر، والكاتبة وسفيرة فلسطين السابقة لدى اليونسكو ليلى شهيد، والمفكر والكاتب والصحفي الفرنسي المعروف آلان غريش، والكاتب والشاعر عبد اللطيف اللعبي، والفنانة التشكيلية أصالة شوك صاحبة الغلاف المميز للكتاب. \n",
            " يحاول الكتاب أن يحفر أركيولوجيا وتاريخيا وأنثروبولوجيا وأدبيا وفنيا في مسار وطن تحوّل إلى رمز، وفكرة تحولت إلى قضية، وقضية توحّدت بشعب، وشعب فاض عن الأرض وتاه في المنفى والشتات والكون، باحثا عن صورة واقعية مطابقة لوطنه الأم المسلوب والمحاصر، فوجد نفسه في رحلة بحثه عن حق وحلم ومفتاح العودة يفتح أبوابا جديدة، ويكتشف قارات فكر بكر، ويخلق أوطانا وليدة في روحه وقلبه المتنصل من المكان والزمان والانتماء، استحضارا لصرخة الشاعر الرمز محمود درويش كل قلوب الناس جنسيتي.. فلتسقطوا عني جواز السفر. \n",
            " يقول الكاتب كريستوف عياد في مقدمة الكتاب في الوقت الذي تبدو فيه فلسطين مهجورة من الجميع، بدءا من الدول العربية، اخترنا العودة إليها بطبيعة الحال للتحدث عن شعبها المشتت بسبب التاريخ والحدود. وأردنا مسح أراضيها المقسمة بين غزة والضفة الغربية على أن تكون القدس مركزا لا يمكن تعقبه. هذه الأراضي التي ضمها الاحتلال الإسرائيلي وابتلعها جدار الفصل العنصري. بعد أن أصبحت رمزا للاستعمار في عالم يمر بعملية إنهاء الاستعمار في النصف الثاني من القرن الـ20، فإن فلسطين لا تنتمي إلى نفسها. إنها قضية ومصدر إلهام للعالم كله. الكوفية علم الثوار في العالم، والفلسطيني لم يعد مجرد جنسية من دون دولة، بل هو رمز الرفض والانصياع والمقاومة. \n",
            " من جانبه أشار جاك لانغ رئيس معهد العالم العربي بباريس إلى أن المعهد أراد من خلال هذا الكتاب الجماعي تقديم صورة إيجابية عن فلسطين؛ لأنه كثيرا ما يختصر الشعب الفلسطيني في النضال وفي المعاناة والحصار، ولكن يُتغافل عن الجانب الإبداعي الثقافي لهذا الشعب الذي يقدم الأفكار الجديدة المتميزة والإبداعات المتفردة إلى العالم. \n",
            " وأشار لانغ -في حديثه السابق للجزيرة نت- إلى أن المعهد أراد أن يقدم هذا الإرث الثقافي المتميز في أبهى صورة إلى القراء، خاصة وهو يحمل قيمة كبيرة للثقافة العالمية، ومن هنا جاء عنوان الكتاب ما تقدمه فلسطين للعالم كشكل من أشكال الاعتراف بإبداعات الشعب الفلسطيني، وإضافاته الكبيرة إلى الثقافة العربية والإنسانية. \n",
            " وأضاف الوضعية المعقدة والظلم الذي يعيشه الشعب الفلسطيني ليس وليد اليوم، وإنما هو نتيجة تراكمات تاريخية طويلة ومنذ عقود. وما يبعث على الحيرة والأسف في الوقت نفسه أننا لاحظنا هذا النسيان الدولي الذي تتعرض له القضية الفلسطينية العادلة، حتى من بعض الدول العربية نفسها. ومن هنا جاء هذا الكتاب، حتى نذكّر بهذه القضية وما يعيشه الشعب الفلسطيني من ظلم ونسيان، ونعيدها إلى مركز الأحداث والاهتمام الدولي. \n",
            " وأشار إلى أن هذا الكتاب يحمل رسالة إلى المجتمع الدولي عن ضرورة الاعتراف بالحقوق المشروعة للشعب الفلسطيني، وأولها الحق في قيام دولة فلسطينية مستقلة. وشدد على أن المجتمع الدولي منقسم اليوم بخصوص القضية الفلسطينية، ولذلك جاء الكتاب بوصفه نوعا من الموقف والصرخة في وجه هذه المواقف المشتتة، وفي وجه الظلم الذي يتعرض له هذا الشعب، وهي صرخة تدعو المجتمع الدولي لضرورة عدم نسيان هذا الشعب المثقف المبدع والمناضل بالأفكار الأصيلة.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "cloud_model_Id=\"deepseek/deepseek-r1:free\"\n",
        "\n",
        "price_per_1m_input_tokens = 0.29\n",
        "price_per_1m_output_tokens = 0.39\n",
        "\n",
        "\n",
        "prompt_tokens =0 # calculate input tokens\n",
        "completion_tokesn=0 # calculate consumption tokens\n",
        "ix=0\n",
        "\n",
        "save_to=join(data_dir,'Datasets','sft.jsonl')\n",
        "\n",
        "for story in tqdm(raw_data):\n",
        "    sample_Details_extraction_messages=[\n",
        "        {\n",
        "            'role':'system',\n",
        "            'content':'\\n'.join([\n",
        "                'you are NLP data parser',\n",
        "                'generate the output in the same story language',\n",
        "                'Extract details as mentioned as text',\n",
        "                'Do not generate any introduction or conclusion',\n",
        "                'you have to extract json details from text according to the pydantic details'\n",
        "            ])\n",
        "        },{\n",
        "            'role':'user',\n",
        "            'content':'\\n'.join([\n",
        "                '## Story:',\n",
        "                story['content'].strip(),\n",
        "                '',\n",
        "\n",
        "                'the pydantic details:',\n",
        "                json.dumps(\n",
        "                    NewsDetails.model_json_schema(),ensure_ascii=False\n",
        "                    ),\n",
        "                '',\n",
        "\n",
        "                'Story Details:',\n",
        "                '```json'\n",
        "            ])\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "      model=cloud_model_Id,\n",
        "      messages=sample_Details_extraction_messages,\n",
        "      temperature=0.2,\n",
        "\n",
        "      )\n",
        "\n",
        "    if response.choices[0].finish_reason !='stop':\n",
        "      prompt_tokens += response.usage.prompt_tokens\n",
        "      continue\n",
        "\n",
        "    llm_response= response.choices[0].message.content\n",
        "    llm_resp_dic =parse_json(llm_response)\n",
        "\n",
        "    if llm_resp_dic is None:\n",
        "      continue\n",
        "\n",
        "    with open(save_to,'a',encoding='utf-8') as dest:\n",
        "      dest.write(json.dumps({\n",
        "            \"id\": ix,\n",
        "            \"story\": story['content'].strip(),\n",
        "            \"task\": \"Extrat the story details into a JSON.\",\n",
        "            \"output_scheme\": json.dumps( NewsDetails.model_json_schema(), ensure_ascii=False ),\n",
        "            \"response\": llm_resp_dic,\n",
        "        }, ensure_ascii=False, default=str)  + \"\\n\" )\n",
        "\n",
        "    ix+=1\n",
        "    prompt_tokens +=response.usage.prompt_tokens\n",
        "    completion_tokesn +=response.usage.completion_tokens\n",
        "\n",
        "\n",
        "    if (ix % 10) == 0:\n",
        "      cost_input =(prompt_tokens / 1_000_000) * price_per_1m_input_tokens\n",
        "      cost_output =(completion_tokesn / 1_000_000) * price_per_1m_output_tokens\n",
        "      total_cost = cost_input + cost_output\n",
        "      print(f\"Processed {ix} samples, Cost: ${total_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "eE2a83-HCud9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_to = join(data_dir, \"datasets\", \"sft.jsonl\")\n",
        "\n",
        "ix = 0\n",
        "for story in tqdm(raw_data):\n",
        "\n",
        "    for targeted_lang in [\"English\", \"French\"]:\n",
        "        sample_translation_messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"You are a professional translator.\",\n",
        "                    \"You will be provided by an Arabic text.\",\n",
        "                    \"You have to translate the text into the `Targeted Language`.\",\n",
        "                    \"Follow the provided Scheme to generate a JSON\",\n",
        "                    \"Do not generate any introduction or conclusion.\"\n",
        "                ])\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"\\n\".join([\n",
        "                    \"## Pydantic Details:\",\n",
        "                    json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
        "                    \"\",\n",
        "\n",
        "                    \"## Targeted Language or Dialect:\",\n",
        "                    targeted_lang,\n",
        "                    \"\",\n",
        "\n",
        "                    \"## Story:\",\n",
        "                    story['content'].strip(),\n",
        "                    \"\",\n",
        "\n",
        "                    \"## Translated Story:\",\n",
        "                    \"```json\"\n",
        "                ])\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "        model=cloud_model_Id,\n",
        "        messages=sample_translation_messages,\n",
        "        temperature=0.2,\n",
        "\n",
        "            )\n",
        "\n",
        "        if response.choices[0].finish_reason != \"stop\":\n",
        "            prompt_tokens += response.usage.prompt_tokens\n",
        "            continue\n",
        "\n",
        "        llm_response = response.choices[0].message.content\n",
        "        llm_resp_dict = parse_json(llm_response)\n",
        "\n",
        "        if not llm_resp_dict:\n",
        "            continue\n",
        "\n",
        "        with open(save_to, \"a\", encoding=\"utf8\") as dest:\n",
        "            dest.write(json.dumps({\n",
        "                \"id\": ix,\n",
        "                \"story\": story['content'].strip(),\n",
        "\n",
        "                \"output_scheme\": json.dumps( TranslatedStory.model_json_schema(), ensure_ascii=False ),\n",
        "                \"task\": f\"You have to translate the story content into {targeted_lang} associated with a title into a JSON.\",\n",
        "\n",
        "                \"response\": llm_resp_dict,\n",
        "            }, ensure_ascii=False, default=str)  + \"\\n\" )\n",
        "\n",
        "        ix += 1\n",
        "        prompt_tokens += response.usage.prompt_tokens\n",
        "        completion_tokens += response.usage.completion_tokens\n",
        "\n",
        "        if(ix % 3) == 0:\n",
        "            cost_input = (prompt_tokens / 1_000_000) * price_per_1m_input_tokens\n",
        "            cost_output = (completion_tokens / 1_000_000) * price_per_1m_output_tokens\n",
        "            total_cost = cost_input + cost_output\n",
        "\n",
        "            print(f\"Iteration {ix}: Total Cost = ${total_cost:.4f} \")"
      ],
      "metadata": {
        "id": "TQ1rFfjwUPY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formate Fine-tuning Dataset"
      ],
      "metadata": {
        "id": "OyUHLvBEc23Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sft_data_path =join(data_dir,'Datasets','sft.jsonl')\n",
        "llm_finetuning_data=[]\n",
        "\n",
        "system_message = \"\\n\".join([\n",
        "    \"You are a professional NLP data parser.\",\n",
        "    \"Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\",\n",
        "    \"Do not generate any introduction or conclusion.\"\n",
        "])\n",
        "\n",
        "for line in open(sft_data_path):\n",
        "  if line.strip() == \"\":\n",
        "    continue\n",
        "\n",
        "  rec =json.loads(line.strip())\n",
        "\n",
        "  llm_finetuning_data.append({\n",
        "      'system':system_message,\n",
        "      'instruction':'\\n'.join([\n",
        "          '# story',\n",
        "          rec['story'],\n",
        "\n",
        "          '# task',\n",
        "          rec['task'],\n",
        "\n",
        "          '#output_schema',\n",
        "          rec['output_scheme'],\n",
        "\n",
        "          '# output json',\n",
        "          \"```json\"\n",
        "\n",
        "          ''\n",
        "      ]),\n",
        "      'input':'',\n",
        "      'output':'\\n'.join([\n",
        "          '```json',\n",
        "          json.dumps(rec['response'],ensure_ascii=False ,default=str),\n",
        "          \"```\"\n",
        "      ]),\n",
        "      'history':[]\n",
        "    })\n",
        "\n",
        "\n",
        "random.Random(101).shuffle(llm_finetuning_data)"
      ],
      "metadata": {
        "id": "QOvVmqCvc1US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(llm_finetuning_data)"
      ],
      "metadata": {
        "id": "9H_PJxWtOuxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90561942-7390-423c-b870-b97289a9ff6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2766"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample_sz= 2700\n",
        "\n",
        "train_ds =llm_finetuning_data[:train_sample_sz]\n",
        "valid_ds=llm_finetuning_data[train_sample_sz:]\n",
        "\n",
        "# create new folder\n",
        "os.makedirs(join(data_dir,'Datasets','LLaMaFactory-Finetuning-data'),exist_ok=True)\n",
        "\n",
        "with open(join(data_dir,'Datasets','LLaMaFactory-Finetuning-data','train.json'),'w') as dest:\n",
        "  json.dump(train_ds,dest,ensure_ascii=False,default=str)\n",
        "\n",
        "with open(join(data_dir,'Datasets','LLaMaFactory-Finetuning-data','valid.json'),'w',encoding='utf8') as dest:\n",
        "  json.dump(valid_ds,dest,ensure_ascii=False,default=str)\n"
      ],
      "metadata": {
        "id": "_GXYElz0_7gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join(data_dir, \"datasets\", \"llamafactory-finetune-data\", \"val.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iDdwTl6W1FK5",
        "outputId": "dce7ecc7-6638-48b0-d39a-2642ad581984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/MyDrive/Fine-Tuning/datasets/llamafactory-finetune-data/val.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Configure LLaMA-Factory for the new datasets\n",
        "\n",
        "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
        "# ```\n",
        "   \"news_finetune_train\": {\n",
        "        \"file_name\": \"/gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/train.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    },\n",
        "    \"news_finetune_val\": {\n",
        "        \"file_name\": \"/gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/valid.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    }\n",
        "# ```\n",
        "\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/apwbkni9\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/c5tf0q90"
      ],
      "metadata": {
        "id": "Pr7BEOoA2Jw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n",
        "### model\n",
        "model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct\n",
        "trust_remote_code: true\n",
        "\n",
        "### method\n",
        "stage: sft\n",
        "do_train: true\n",
        "finetuning_type: lora\n",
        "lora_rank: 64\n",
        "lora_target: all\n",
        "\n",
        "### dataset\n",
        "dataset: news_finetune_train\n",
        "template: qwen\n",
        "cutoff_len: 3500\n",
        "max_samples: 550\n",
        "overwrite_cache: true\n",
        "preprocessing_num_workers: 16\n",
        "dataloader_num_workers: 4\n",
        "\n",
        "### output\n",
        "resume_from_checkpoint: /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models/checkpoint-500\n",
        "output_dir: /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models\n",
        "logging_steps: 10\n",
        "save_steps: 50\n",
        "plot_loss: true\n",
        "# overwrite_output_dir: true\n",
        "save_only_model: false\n",
        "\n",
        "### train\n",
        "per_device_train_batch_size: 1\n",
        "gradient_accumulation_steps: 8\n",
        "learning_rate: 1.0e-4\n",
        "num_train_epochs: 3.0\n",
        "lr_scheduler_type: cosine\n",
        "warmup_ratio: 0.1 # don not change learning rate for first 10 % from data\n",
        "bf16: true # store half of weights in memory\n",
        "ddp_timeout: 180000000\n",
        "resume_from_checkpoint: null\n",
        "\n",
        "### eval\n",
        "eval_dataset: news_finetune_val\n",
        "# val_size: 0.1\n",
        "per_device_eval_batch_size: 1\n",
        "eval_strategy: steps\n",
        "eval_steps: 100\n",
        "\n",
        "\n",
        "report_to: wandb\n",
        "run_name: news_finetuning_llamafactory\n",
        "\n",
        "# push_to_hub: true\n",
        "# export_hub_model_id : \"shroukAdel/news_analyzer\"\n",
        "# hub_private_repo: true\n",
        "# hub_strategy: checkpoint # update for every checkpoint\n"
      ],
      "metadata": {
        "id": "2p1KtNOywExy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6fe725-3422-4b8c-d711-9fc1fc00fe30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd LLaMA-Factory && pip install -e .\n"
      ],
      "metadata": {
        "id": "OhAjILweZOzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd LLaMA-Factory/ && llamafactory-cli train /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml"
      ],
      "metadata": {
        "id": "By_urE-OWV4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0d613f-29da-4879-f0ce-829af498be52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 09:30:15.126343: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747647015.321576    5359 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747647015.377313    5359 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 09:30:15.781042: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[INFO|2025-05-19 09:30:29] llamafactory.hparams.parser:143 >> Resuming training from /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models/checkpoint-500.\n",
            "[INFO|2025-05-19 09:30:29] llamafactory.hparams.parser:143 >> Change `output_dir` or use `overwrite_output_dir` to avoid.\n",
            "[INFO|2025-05-19 09:30:29] llamafactory.hparams.parser:401 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16\n",
            "tokenizer_config.json: 100% 7.30k/7.30k [00:00<00:00, 30.3MB/s]\n",
            "vocab.json: 100% 2.78M/2.78M [00:00<00:00, 3.07MB/s]\n",
            "merges.txt: 100% 1.67M/1.67M [00:00<00:00, 2.34MB/s]\n",
            "tokenizer.json: 100% 7.03M/7.03M [00:00<00:00, 24.5MB/s]\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:33,966 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:33,967 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:33,967 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:33,967 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:33,967 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:33,967 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:33,967 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2304] 2025-05-19 09:30:34,358 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "config.json: 100% 660/660 [00:00<00:00, 3.84MB/s]\n",
            "[INFO|configuration_utils.py:696] 2025-05-19 09:30:35,532 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:768] 2025-05-19 09:30:35,533 >> Model config Qwen2Config {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:35,735 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:35,735 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:35,735 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:35,735 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:35,735 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:35,735 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-05-19 09:30:35,735 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2304] 2025-05-19 09:30:36,091 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|2025-05-19 09:30:36] llamafactory.data.loader:143 >> Loading dataset /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/train.json...\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 2700 examples [00:04, 644.26 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 550/550 [00:00<00:00, 734.00 examples/s] \n",
            "[INFO|2025-05-19 09:30:45] llamafactory.data.loader:143 >> Loading dataset /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/valid.json...\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 66 examples [00:00, 2359.66 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 66/66 [00:00<00:00, 143.63 examples/s]\n",
            "Running tokenizer on dataset (num_proc=16): 100% 550/550 [00:19<00:00, 28.22 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 2, 3364, 198, 29825, 55334, 126458, 143507, 45577, 5703, 123860, 39423, 20064, 131723, 63237, 125007, 128538, 123877, 126385, 73441, 128416, 39434, 124837, 13325, 59842, 8532, 125192, 124766, 125559, 17166, 132748, 128769, 125766, 124006, 77273, 39434, 132579, 53710, 124267, 124114, 123987, 68785, 129943, 73274, 130527, 74315, 124522, 37524, 27490, 124179, 68238, 65398, 84532, 13, 715, 124766, 124283, 124543, 53479, 124322, 25871, 142734, 126655, 125007, 128305, 123877, 126385, 73441, 39434, 133498, 23364, 132137, 47632, 142734, 68785, 128248, 135638, 53479, 127172, 137499, 123877, 124636, 123890, 73441, 128562, 124006, 53479, 58656, 135430, 68785, 133950, 63415, 126385, 73441, 124265, 127467, 124080, 41593, 124636, 124072, 123904, 123963, 47632, 128405, 124837, 124082, 47632, 13, 715, 128388, 125007, 123877, 126385, 73441, 135087, 73441, 128718, 133020, 132070, 125434, 124514, 124082, 70604, 37524, 127799, 132070, 17166, 124480, 39423, 68785, 124838, 125481, 136510, 47632, 123894, 123860, 124766, 126385, 73441, 12961, 11071, 127476, 126815, 81778, 43635, 132033, 124766, 126385, 73441, 123961, 126019, 73441, 124072, 125916, 123832, 68785, 128416, 128510, 125077, 125709, 124130, 25871, 134017, 17166, 132748, 13, 715, 128827, 142201, 74315, 124522, 123961, 12653, 65398, 84532, 68785, 140880, 130283, 77703, 14558, 124346, 125143, 124226, 126350, 39434, 124104, 72804, 128305, 123877, 126385, 73441, 68785, 128259, 125027, 124009, 129919, 73274, 130151, 125637, 124678, 124476, 13325, 125646, 133843, 23224, 91344, 130519, 20931, 135542, 125701, 13, 715, 124838, 129013, 128443, 68785, 73274, 124464, 123860, 128248, 124793, 129843, 73274, 131744, 124793, 44330, 126924, 125007, 73274, 64604, 8532, 123995, 50243, 92381, 124653, 128248, 124080, 123941, 25871, 135276, 126208, 125215, 25871, 126198, 128754, 126214, 128280, 124220, 126924, 126298, 125007, 140620, 124661, 59842, 8532, 124671, 128248, 77703, 124144, 125011, 128248, 17166, 132748, 129521, 125559, 13, 715, 37524, 123860, 21360, 125313, 126899, 128707, 123862, 125653, 125007, 130616, 124261, 124220, 126924, 63237, 129193, 37524, 125657, 25871, 124665, 129636, 128259, 132338, 128636, 129581, 125490, 125108, 127930, 131351, 73441, 624, 2, 3383, 198, 2610, 614, 311, 14683, 279, 3364, 2213, 1119, 6364, 5815, 448, 264, 2265, 1119, 264, 4718, 624, 2, 3006, 25371, 198, 4913, 13193, 788, 5212, 53242, 6112, 788, 5212, 4684, 788, 330, 50, 53276, 24531, 2265, 315, 279, 3669, 3364, 10465, 330, 60992, 788, 220, 17, 20, 20, 11, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 10869, 497, 330, 1313, 788, 330, 917, 14345, 330, 53242, 7495, 788, 5212, 4684, 788, 330, 81016, 2213, 315, 279, 3669, 3364, 10465, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 8883, 497, 330, 1313, 788, 330, 917, 9207, 2137, 330, 6279, 788, 4383, 53242, 6112, 497, 330, 53242, 7495, 7914, 330, 2102, 788, 330, 81016, 17938, 497, 330, 1313, 788, 330, 1700, 16707, 2, 2550, 2951, 198, 73594, 2236, 151645, 198, 151644, 77091, 198, 73594, 2236, 198, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 532, 73594, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "# story\n",
            "حذرت مجلة فاينانس تست من أن بعض الأدوية قد تهدد سلامة وأمان القيادة لتسببها في تأخر ردة الفعل، مما يرفع خطر وقوع حادث. \n",
            " وأوضحت المجلة الألمانية أن هذه الأدوية تشمل مسكنات الألم، على سبيل المثال المواد الأفيونية ومنها المورفين، وكذلك أدوية الصداع النصفي والمنومات والمهدئات. \n",
            " كما أن الأدوية النفسية مثل مضادات الاكتئاب ومضادات الذهان، وبعض قطرات العين وأدوية ارتفاع ضغط الدم وأدوية الحساسية والسكري، قد تمثل مشكلة أثناء القيادة. \n",
            " ولتجنب خطر الحوادث، ينبغي عدم قيادة السيارة عند تناول هذه الأدوية، لا سيما عندما يشعر المرء بالدوار والنعاس وضعف التركيز. \n",
            " وبشكل عام، يتعين على أي شخص يتناول أي دواء أن يُلقي نظرة على النشرة الداخلية لمعرفة ما إذا كان هذا الدواء يمكن أن يؤثر سلبا على قدرته على القيادة بأمان. \n",
            " وينبغي أيضا مراعاة أن توفر الدواء من دون وصفة طبية لا يعني أنه ليس له آثار جانبية.\n",
            "# task\n",
            "You have to translate the story content into English associated with a title into a JSON.\n",
            "#output_schema\n",
            "{\"properties\": {\"translated_title\": {\"description\": \"Suggested translated title of the news story.\", \"maxLength\": 255, \"minLength\": 5, \"title\": \"Translated Title\", \"type\": \"string\"}, \"translated_content\": {\"description\": \"Translated content of the news story.\", \"minLength\": 5, \"title\": \"Translated Content\", \"type\": \"string\"}}, \"required\": [\"translated_title\", \"translated_content\"], \"title\": \"TranslatedStory\", \"type\": \"object\"}\n",
            "# output json\n",
            "```json<|im_end|>\n",
            "<|im_start|>assistant\n",
            "```json\n",
            "{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}\n",
            "```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 198, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 532, 73594, 151645, 198]\n",
            "labels:\n",
            "```json\n",
            "{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}\n",
            "```<|im_end|>\n",
            "\n",
            "Running tokenizer on dataset (num_proc=16): 100% 66/66 [00:11<00:00,  5.55 examples/s]\n",
            "eval example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 2, 3364, 198, 129714, 131801, 27846, 130950, 77273, 39434, 123890, 20064, 68785, 128374, 123877, 136176, 124280, 124172, 125767, 25871, 129744, 73441, 68785, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 68785, 131933, 123894, 129600, 77273, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 5703, 124613, 68785, 131933, 44330, 125138, 130771, 124072, 132970, 68785, 131933, 126453, 128559, 124325, 123894, 65398, 128518, 68785, 129673, 128248, 74315, 124284, 73441, 124012, 129600, 124172, 125591, 126212, 138928, 140765, 125006, 127570, 47632, 124072, 134700, 124058, 125573, 73441, 68785, 133707, 77703, 11071, 124669, 128305, 134515, 128261, 126815, 124011, 14293, 128794, 138928, 43982, 125516, 123961, 123829, 43635, 13, 715, 12961, 133326, 14293, 124080, 125940, 143825, 20064, 73441, 125007, 124058, 127524, 47632, 130771, 73441, 128261, 63415, 125150, 14293, 129387, 68238, 125229, 47632, 126198, 128325, 124437, 125520, 68785, 63237, 128374, 44330, 46586, 58656, 220, 17, 15, 16, 19, 68785, 128416, 27846, 47632, 14293, 130656, 127837, 23364, 125154, 123963, 127837, 128464, 131132, 131037, 127923, 131045, 13, 129828, 130519, 53479, 123941, 73771, 135590, 68785, 128325, 142402, 126409, 47632, 23364, 35038, 124352, 123890, 73441, 139412, 12961, 10176, 125645, 14293, 129225, 125849, 135376, 132351, 68785, 128962, 20064, 126453, 128559, 124325, 123894, 65398, 128518, 37524, 136341, 124006, 132294, 126483, 93543, 124006, 131936, 129200, 84996, 126413, 13, 128478, 125007, 126731, 124330, 14558, 55891, 126931, 138752, 126196, 77703, 131910, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 63415, 129714, 17166, 130076, 128252, 137623, 124265, 124261, 68785, 124766, 141068, 55057, 125696, 130170, 123862, 126513, 133483, 39434, 129989, 27846, 124938, 55057, 125069, 130741, 25871, 128252, 124147, 124284, 68785, 27846, 129600, 127837, 63237, 123894, 125629, 13, 715, 128474, 14293, 126453, 31073, 124325, 124058, 125573, 73441, 124665, 135590, 135377, 128707, 32790, 133955, 125006, 127570, 47632, 124269, 124082, 91344, 73441, 68785, 37524, 124621, 126458, 85153, 126415, 123862, 124138, 128252, 123913, 21360, 124181, 138751, 14558, 68785, 23364, 130353, 73441, 137007, 77703, 11071, 124669, 138928, 128261, 128962, 124687, 129080, 135172, 130995, 77703, 126968, 14558, 124838, 125343, 73771, 47632, 37524, 124642, 73441, 68785, 128388, 37524, 125657, 128349, 125637, 32790, 29825, 123890, 127560, 25871, 68785, 127555, 124009, 50243, 41593, 128471, 131695, 14558, 127837, 77703, 131910, 126453, 31073, 124325, 13, 715, 128641, 124009, 39434, 125169, 124269, 69682, 14558, 128586, 77273, 135275, 124072, 129609, 68785, 124072, 126119, 127221, 133527, 123890, 68785, 93153, 124082, 11798, 95975, 125637, 32790, 133955, 126208, 124703, 124138, 131695, 125358, 124837, 138751, 14558, 86941, 123904, 95975, 125838, 82168, 79820, 123860, 125006, 133063, 77703, 124392, 59842, 125090, 73771, 13325, 68785, 127955, 16157, 73441, 128464, 131651, 68785, 129869, 137204, 56794, 127570, 47632, 141396, 63237, 63415, 124514, 130945, 133205, 124665, 124423, 127837, 128402, 124169, 27490, 127837, 68785, 131813, 77703, 131910, 55891, 126931, 138752, 126502, 125106, 127837, 125006, 131610, 68785, 63237, 128374, 124058, 124363, 39423, 77273, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 13, 715, 128280, 134466, 126214, 128763, 84532, 125275, 127726, 136666, 63415, 124014, 77273, 132745, 130519, 12961, 124126, 35244, 70604, 14558, 82168, 65398, 73274, 57859, 123904, 23364, 129614, 39434, 127809, 124035, 142847, 124072, 124706, 95975, 20064, 124080, 125089, 16157, 68785, 37524, 124438, 131032, 63237, 94957, 132119, 129755, 123904, 14558, 126212, 123894, 125152, 47632, 132793, 128248, 94957, 29825, 32790, 123980, 74315, 124284, 128707, 32790, 29825, 126761, 128577, 56794, 57859, 125559, 85153, 127878, 94957, 125313, 93543, 128307, 128657, 133548, 132674, 86941, 84532, 14558, 132280, 68785, 128523, 129445, 124082, 31073, 129174, 12961, 41593, 125346, 123920, 74315, 124284, 128295, 124388, 70604, 220, 17, 20, 135621, 123978, 124412, 220, 17, 15, 17, 16, 68785, 130117, 123920, 63237, 128773, 53479, 139600, 129249, 131045, 68785, 124072, 127099, 127116, 128883, 130881, 47632, 124072, 124938, 124691, 128261, 12961, 14293, 64604, 73771, 137867, 14293, 56794, 124210, 27490, 127837, 68785, 129833, 73274, 125657, 124006, 74315, 140636, 126543, 77703, 124392, 59842, 125090, 73771, 13325, 27846, 124074, 31382, 124341, 124187, 133642, 124072, 13325, 124514, 47632, 126113, 13, 715, 133431, 12961, 27490, 124706, 23224, 63415, 125718, 21360, 55891, 124035, 129899, 126513, 73771, 94957, 125313, 93543, 23364, 125493, 68785, 126420, 128321, 126815, 11071, 125729, 13, 715, 77703, 131910, 55891, 126931, 138752, 128280, 39434, 125766, 77273, 59842, 95198, 43982, 35038, 10176, 63237, 17166, 124519, 27490, 132070, 143098, 55334, 124511, 68785, 92072, 124144, 14293, 126195, 139589, 77703, 126968, 37524, 142539, 125027, 91344, 73441, 124766, 129895, 70604, 128562, 125362, 47632, 68785, 37524, 141470, 133547, 73441, 77273, 135275, 124072, 129609, 13, 37524, 123978, 37524, 125657, 16157, 27846, 124074, 31382, 124464, 20064, 124636, 131795, 125669, 124863, 124072, 133672, 124641, 56794, 133063, 129814, 134898, 13, 126420, 12961, 129080, 14293, 138928, 27846, 134681, 124006, 128252, 63415, 124405, 25871, 132266, 137024, 140597, 55334, 73441, 68785, 129869, 63415, 129152, 91335, 5703, 93153, 124388, 124421, 128412, 68785, 138827, 23364, 41593, 124405, 123995, 128412, 68785, 37524, 11798, 130030, 134035, 92072, 126413, 133612, 65398, 128261, 43982, 64604, 126780, 14293, 128794, 138928, 129185, 85153, 124983, 98719, 129445, 50243, 20064, 35244, 25871, 129431, 77273, 128586, 220, 17, 15, 16, 16, 68785, 27846, 134736, 129445, 12961, 124126, 35244, 70604, 47632, 39434, 130910, 73441, 68238, 127347, 73441, 77273, 133483, 68785, 85153, 21360, 73771, 39423, 125069, 125520, 220, 16, 19, 134340, 124703, 123890, 130277, 220, 17, 15, 16, 16, 13, 715, 12961, 136204, 53479, 124668, 43635, 133527, 124072, 126123, 123938, 39434, 127923, 127837, 63237, 138928, 128577, 56794, 57859, 125559, 52157, 20931, 133176, 138752, 37524, 130163, 124642, 128412, 68785, 128762, 128305, 134515, 63415, 124148, 14293, 128248, 138990, 124006, 13, 37524, 129883, 128755, 124006, 68785, 45577, 35038, 124085, 27846, 124179, 126023, 68785, 125502, 127207, 23364, 136596, 127837, 93153, 124122, 35038, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 131268, 65398, 124220, 5703, 135063, 68785, 128562, 127188, 125572, 124104, 133065, 68785, 37524, 136961, 124478, 43635, 124394, 53479, 124811, 13, 37524, 127029, 12961, 125011, 49388, 127837, 128883, 128074, 124325, 124058, 125573, 73441, 27846, 124343, 27490, 124058, 124328, 98719, 47632, 130771, 73441, 68785, 124209, 135425, 128307, 50243, 20931, 125011, 126453, 31073, 124325, 50243, 124636, 127837, 77703, 124330, 23224, 127837, 68785, 129353, 43982, 125516, 37524, 84532, 125955, 39434, 132596, 59842, 8532, 125192, 85153, 124328, 98719, 130377, 37524, 124938, 124691, 124006, 37524, 129152, 127837, 125006, 130718, 128405, 124322, 25871, 141912, 126510, 125088, 92381, 124325, 56794, 125523, 126453, 31073, 124325, 128402, 124944, 47632, 39434, 129955, 124006, 13, 715, 128641, 129163, 126556, 128546, 124042, 124325, 63237, 128280, 17166, 137378, 124080, 126409, 124082, 68785, 56794, 33090, 127477, 128538, 123877, 124522, 95975, 77273, 133483, 128252, 127115, 124420, 125653, 55891, 126931, 138752, 68785, 82611, 124675, 124422, 124006, 39434, 124423, 73771, 131922, 39434, 129422, 124412, 137024, 68785, 130444, 39434, 125267, 27846, 124621, 124669, 124012, 128026, 140425, 130462, 126453, 31073, 52704, 73771, 124325, 77273, 137637, 138751, 73441, 68785, 129308, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128261, 138073, 73771, 63415, 128074, 49388, 124006, 27846, 47632, 73771, 25871, 37524, 124647, 126510, 68785, 124793, 128478, 77703, 127415, 25871, 125006, 43635, 127206, 128264, 124058, 130353, 98719, 68785, 37524, 129152, 45577, 132412, 98719, 130771, 124072, 135617, 25871, 124058, 125573, 126319, 68785, 128718, 124172, 124420, 14558, 124058, 125573, 14558, 129200, 127818, 131118, 92072, 127602, 68785, 128307, 53710, 124898, 27846, 129345, 16157, 44330, 23224, 125187, 134541, 126510, 130160, 138928, 68785, 27846, 131271, 16157, 142685, 124723, 127837, 50243, 5703, 125940, 127837, 68785, 132402, 27846, 125657, 125011, 142887, 126510, 13, 715, 128671, 141183, 126453, 31073, 124325, 124058, 125573, 73441, 128261, 63415, 64604, 124983, 137648, 128586, 220, 16, 24, 22, 17, 129458, 142641, 77273, 142001, 17166, 125664, 73771, 77273, 44330, 125072, 125187, 39434, 129422, 124412, 137024, 68785, 128261, 129106, 53710, 124898, 124006, 131425, 130353, 98719, 23364, 124621, 125815, 85153, 125573, 73441, 68785, 128474, 125007, 129106, 126731, 127616, 124172, 126277, 123860, 125088, 92381, 124325, 129046, 128443, 220, 17, 15, 16, 19, 68785, 27846, 47632, 33090, 124642, 85153, 125629, 70604, 124006, 23364, 125930, 127837, 63237, 126455, 124388, 125756, 68785, 128562, 29825, 124006, 123894, 125123, 73441, 77273, 77703, 11071, 124669, 124006, 68785, 74315, 41593, 125155, 127837, 77273, 124080, 39697, 123862, 47632, 138751, 73441, 68785, 129869, 137204, 129046, 132371, 73441, 128248, 127072, 35038, 138751, 14558, 73771, 13, 715, 128478, 125007, 55891, 126931, 138752, 53710, 127477, 74315, 125395, 128349, 138787, 127837, 13, 129828, 128707, 73771, 81778, 14293, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 77273, 94957, 127106, 68785, 37524, 126666, 14293, 129431, 128420, 124130, 127837, 134933, 53710, 128722, 68785, 23364, 123987, 124282, 12961, 124543, 126900, 124006, 132371, 73441, 128248, 138752, 37524, 124223, 124669, 124006, 136973, 68785, 63237, 85153, 123987, 39423, 130570, 124006, 128252, 124058, 123987, 39423, 126195, 50243, 14293, 123829, 33090, 124006, 124080, 16157, 126510, 13, 715, 126731, 124466, 55891, 126931, 138752, 126196, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 73274, 126624, 133483, 128252, 137623, 124265, 124261, 68785, 129943, 63415, 127930, 23364, 35244, 5703, 124387, 128967, 93153, 124388, 31382, 124172, 127288, 37524, 130163, 124642, 25871, 137637, 138751, 73441, 715, 37524, 11071, 126106, 124012, 129600, 128307, 126208, 73274, 138210, 52704, 128252, 129968, 126212, 127647, 20064, 46586, 123860, 68785, 128843, 124080, 124787, 125168, 131205, 68785, 129308, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 68785, 131795, 140478, 128248, 127560, 14558, 53479, 127207, 129185, 17166, 135911, 73441, 126543, 77703, 124392, 59842, 125090, 73771, 13325, 68785, 126857, 16157, 93543, 53479, 81778, 130010, 124623, 126418, 123860, 128443, 68238, 126703, 129839, 68785, 132525, 124075, 128862, 125572, 125291, 128755, 68238, 126703, 43982, 124641, 131482, 128307, 63415, 64604, 129955, 123913, 126336, 23364, 124085, 124387, 127837, 128577, 130153, 82168, 11071, 125591, 39434, 13325, 127300, 94957, 39697, 124811, 47632, 129839, 73441, 68785, 68238, 124125, 12961, 125011, 49388, 137024, 125490, 13, 715, 129581, 128280, 37524, 129523, 68785, 126420, 59842, 35038, 124675, 137024, 140597, 55334, 73441, 128252, 50243, 123941, 77703, 131910, 138928, 131695, 124012, 123832, 124267, 124269, 124131, 73441, 125006, 135463, 143825, 20064, 73441, 128577, 56794, 130389, 132866, 130063, 124793, 63415, 124014, 77273, 123894, 69423, 25871, 128252, 17166, 58656, 98719, 68785, 128388, 73274, 11071, 124848, 126543, 59842, 125090, 73771, 13325, 136075, 127837, 13, 715, 126420, 128342, 137024, 68785, 23364, 31073, 124126, 55891, 126931, 138752, 63237, 52157, 29825, 124282, 123961, 83827, 138751, 14558, 68785, 129271, 124811, 91344, 125700, 123904, 25871, 68785, 130245, 129521, 58656, 124181, 17166, 124181, 124015, 123862, 68785, 77273, 139268, 23364, 129806, 134470, 137410, 68785, 126513, 130656, 125637, 32790, 133955, 127560, 25871, 129174, 63415, 124148, 14293, 138928, 128248, 85153, 20064, 27490, 124330, 39434, 129104, 29825, 124138, 125006, 127570, 47632, 124269, 124082, 91344, 73441, 128416, 68238, 64604, 124131, 128953, 128259, 53710, 33090, 124511, 128985, 68785, 129265, 74315, 125633, 55891, 126931, 138752, 126214, 59842, 125260, 127837, 128562, 43635, 123995, 127837, 68785, 77273, 133114, 125237, 137024, 13, 715, 124072, 132777, 68785, 134436, 128305, 53479, 124653, 130528, 128261, 129106, 128857, 53710, 124851, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 13, 129828, 59842, 125173, 56794, 133501, 123894, 129600, 125007, 53710, 124851, 14293, 128264, 39434, 81778, 124420, 14293, 126195, 129458, 124636, 55334, 68238, 124613, 126453, 31073, 124325, 124058, 125573, 73441, 130394, 125106, 31382, 77703, 131910, 85153, 23224, 132157, 124172, 125259, 25871, 220, 19, 24, 63237, 63415, 124224, 220, 20, 22, 77703, 124420, 14558, 127837, 68785, 128307, 12961, 14293, 64604, 73771, 137867, 128763, 133810, 130656, 53710, 124082, 125309, 77273, 135333, 129895, 129194, 220, 17, 15, 17, 17, 13, 715, 126208, 39434, 124232, 69682, 131209, 123894, 129600, 27846, 130076, 55891, 124035, 129899, 124172, 125259, 25871, 68785, 128523, 128325, 44330, 35244, 72804, 124138, 77273, 85153, 125248, 70604, 37524, 29825, 128862, 73771, 126195, 140591, 93153, 124122, 73771, 56794, 124079, 25871, 133674, 68785, 130444, 39434, 8532, 124880, 14293, 128252, 77703, 131910, 126453, 31073, 124325, 124058, 125573, 73441, 13, 126420, 123877, 91335, 55057, 63237, 128349, 68785, 125007, 55891, 124035, 129899, 124172, 125259, 25871, 126198, 73274, 130234, 123890, 128523, 128438, 134689, 23364, 139191, 47632, 134541, 126510, 63237, 128474, 137024, 68785, 56794, 130110, 49388, 124138, 126436, 11798, 73771, 85153, 125248, 70604, 37524, 124464, 43635, 95198, 23364, 126780, 27490, 85153, 125573, 14558, 131268, 123963, 14558, 135172, 130995, 126906, 13, 715, 128523, 125088, 125362, 47632, 136355, 128261, 39434, 39697, 124423, 44330, 126119, 124006, 126195, 130771, 124072, 127614, 126212, 138355, 68785, 128248, 125040, 131910, 131534, 128586, 143826, 125006, 138391, 125088, 92381, 124325, 132474, 70604, 73441, 123877, 124273, 27490, 77273, 39434, 123890, 20064, 68785, 53710, 124851, 14293, 124058, 55334, 134056, 56794, 129305, 126453, 31073, 124325, 124058, 125573, 73441, 142740, 128474, 27846, 57859, 124511, 128962, 70604, 124280, 68785, 56794, 126692, 29825, 128707, 124937, 53710, 27490, 125275, 126208, 127809, 124290, 124114, 20064, 65398, 68785, 128307, 128657, 39697, 124423, 16157, 125637, 32790, 29825, 56794, 11071, 124082, 91344, 25871, 140779, 126113, 68785, 131268, 65398, 124220, 5703, 135063, 13, 715, 130267, 126198, 126731, 124404, 130622, 126453, 31073, 124325, 124058, 125573, 73441, 129185, 43982, 136692, 13, 131649, 128342, 124478, 128655, 124678, 136709, 59842, 125750, 128402, 141905, 68785, 128762, 17166, 124210, 125492, 49388, 128252, 77703, 11071, 124669, 124006, 124766, 128074, 49388, 124006, 77273, 45577, 57859, 73771, 124080, 39697, 123862, 47632, 68785, 126198, 73274, 130234, 126815, 23224, 124394, 127837, 68785, 128342, 126208, 50243, 124388, 63237, 124079, 10176, 127837, 13, 130267, 126198, 73274, 134224, 59842, 124035, 31382, 127837, 82168, 129094, 123832, 127837, 128967, 63415, 124125, 70604, 37524, 126385, 123862, 14558, 130283, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128248, 139066, 63237, 128288, 124265, 80970, 124668, 47632, 128261, 23364, 64604, 11798, 124543, 129046, 13, 715, 77273, 76841, 91344, 25871, 130226, 73441, 77703, 126968, 73441, 50243, 64604, 123941, 14293, 133427, 124343, 127837, 128967, 129458, 124636, 55334, 63415, 128074, 49388, 37524, 124621, 124669, 124172, 127288, 124058, 125573, 14558, 77273, 39434, 123890, 20064, 68785, 63415, 124347, 124172, 124420, 14558, 124058, 125573, 14558, 68785, 131268, 65398, 125110, 70604, 123832, 68785, 128252, 126198, 128962, 124009, 124006, 39434, 133172, 10176, 8803, 116, 127706, 130283, 129458, 124636, 55334, 63415, 128074, 49388, 124172, 127288, 124058, 125573, 14558, 68785, 128523, 133455, 73274, 64604, 11798, 124675, 124476, 133812, 128307, 128259, 39434, 64604, 139178, 63415, 128074, 49388, 16157, 37524, 124621, 124669, 16157, 68785, 129308, 124012, 124014, 25871, 128261, 39434, 141707, 77273, 133474, 128248, 128858, 123877, 130211, 11798, 77273, 39434, 123890, 20064, 68785, 86941, 135328, 25871, 130759, 128248, 128305, 124478, 49388, 127472, 125653, 128261, 39434, 131377, 128794, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 496, 56794, 49388, 127472, 125653, 39434, 125704, 128438, 126492, 125267, 124172, 127288, 124058, 125573, 14558, 128248, 86941, 20931, 73771, 43982, 52704, 20931, 123832, 14293, 13, 715, 126208, 73274, 138210, 52704, 132474, 126409, 126350, 130283, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128342, 124009, 138073, 73771, 124642, 125502, 133498, 23364, 134363, 25871, 132371, 73441, 128248, 127072, 35038, 138751, 14558, 68785, 37524, 124438, 39434, 124223, 31073, 126453, 31073, 124325, 129521, 29825, 123995, 128412, 130771, 73441, 128248, 128280, 130208, 13, 128762, 55891, 126931, 138752, 128671, 128416, 59842, 125173, 14293, 136656, 128252, 128349, 129185, 17166, 135911, 73441, 68785, 63237, 128374, 85153, 123987, 39423, 128464, 133624, 124476, 31073, 124466, 128248, 137637, 138751, 73441, 13, 715, 137687, 53479, 124062, 124267, 56794, 11071, 130025, 125192, 138752, 68785, 129308, 63237, 39434, 131731, 130570, 128587, 17166, 124181, 124015, 123862, 68785, 129308, 63237, 39434, 133033, 128248, 130759, 94957, 41593, 124623, 14293, 68785, 128562, 39434, 127207, 126195, 50243, 14293, 123829, 124649, 124080, 16157, 126510, 13, 126857, 65398, 14293, 128248, 128349, 68785, 126513, 131694, 43635, 14293, 129225, 124434, 124006, 126906, 132371, 73441, 128248, 132919, 124072, 132970, 132919, 73441, 68785, 126420, 128523, 128248, 138324, 132919, 73441, 125637, 32790, 124290, 125006, 134971, 73771, 68785, 131247, 126198, 73274, 64604, 124676, 77273, 128538, 125088, 136077, 132919, 73441, 68785, 74315, 41593, 125155, 127837, 17166, 124519, 27490, 132070, 128261, 39434, 124146, 73771, 16157, 128252, 138928, 13, 715, 129581, 128280, 37524, 129523, 68785, 126420, 128342, 55891, 126931, 138752, 63415, 123987, 124126, 128464, 133624, 128248, 23364, 124347, 124571, 125088, 125362, 47632, 53479, 124233, 126987, 77273, 23364, 123940, 124572, 25871, 138752, 68785, 128718, 63237, 125362, 14293, 27910, 14558, 132823, 73274, 27490, 92381, 128402, 123940, 124572, 123890, 68785, 37524, 132621, 125011, 124009, 124476, 124434, 65398, 53479, 124421, 68785, 125449, 98719, 124376, 128248, 126198, 77703, 125962, 128342, 124006, 85153, 126123, 124669, 63237, 141405, 124269, 124131, 73441, 27846, 134440, 128920, 128248, 39434, 124453, 95198, 63415, 126336, 123938, 13, 128280, 132338, 125007, 138928, 93153, 125849, 55334, 14293, 128523, 128248, 129366, 124172, 127288, 68785, 53479, 35244, 72804, 37524, 29825, 91335, 27846, 137321, 128264, 50243, 124636, 39434, 124138, 25871, 124114, 20064, 65398, 53479, 124421, 128248, 125088, 125362, 128885, 13, 715, 128280, 124080, 39697, 124179, 125006, 126992, 123904, 25871, 128248, 137637, 138751, 73441, 68785, 132178, 124876, 65398, 126453, 31073, 124325, 124058, 125573, 73441, 63237, 131132, 47632, 136837, 138065, 124006, 125088, 41593, 125155, 129387, 77703, 126968, 127837, 77273, 140691, 124476, 127570, 47632, 68785, 82168, 130362, 130684, 63237, 131997, 98719, 124766, 20064, 47632, 55334, 25871, 130771, 73274, 129883, 123890, 126195, 92072, 126406, 124138, 68785, 128306, 124232, 73771, 132280, 126195, 53710, 124851, 124138, 128349, 27846, 124283, 128722, 13, 715, 129828, 12961, 126020, 123877, 46586, 125908, 86941, 125291, 125449, 23364, 20064, 124915, 68785, 128631, 127564, 77273, 124172, 127288, 124058, 125573, 14558, 68785, 125007, 126453, 31073, 124325, 124058, 125573, 73441, 39434, 137427, 124476, 126897, 73441, 140286, 25871, 128248, 138752, 68785, 74315, 41593, 125155, 127837, 77273, 124080, 39697, 123862, 47632, 138751, 73441, 129271, 128074, 49388, 142887, 126510, 126249, 47632, 73771, 25871, 124265, 65398, 124653, 134035, 68785, 128660, 126198, 63415, 31073, 91335, 128912, 63237, 53479, 138611, 123860, 77273, 130771, 124220, 46586, 125729, 68785, 77273, 142011, 50243, 64604, 123941, 138147, 125088, 138473, 77273, 133407, 63237, 136077, 85153, 126010, 73441, 39434, 123890, 20064, 73441, 124766, 33090, 125197, 73441, 13, 715, 128259, 73274, 125638, 124148, 143331, 128248, 132371, 73441, 128248, 138752, 68785, 128264, 128248, 131865, 25871, 124172, 127288, 124058, 125573, 14558, 68785, 128264, 128248, 131132, 47632, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 13, 45577, 133299, 128420, 124209, 124328, 25871, 128261, 134684, 124636, 125110, 125275, 68785, 128388, 73274, 124676, 13, 130208, 137961, 27846, 124985, 124130, 25871, 125027, 91344, 73441, 77273, 123894, 124992, 68785, 39434, 137402, 127586, 11071, 124346, 132793, 77273, 126453, 5703, 124613, 47632, 123894, 65398, 128518, 68785, 37524, 126666, 124172, 127288, 128321, 124114, 14558, 124224, 77273, 124080, 39697, 123862, 47632, 126212, 137024, 37524, 124446, 123963, 124006, 68785, 37524, 123997, 127347, 93153, 124388, 31382, 127647, 20064, 124966, 142887, 126510, 68785, 37524, 57859, 125559, 23364, 129614, 124114, 124224, 126212, 141405, 68785, 37524, 132212, 143056, 53479, 125837, 73441, 124072, 127393, 73441, 68785, 134018, 123832, 47632, 27846, 131610, 128510, 129198, 130377, 13, 715, 128280, 126198, 126731, 125629, 16157, 143385, 31073, 123961, 127347, 73441, 128438, 68785, 128261, 140260, 125007, 136930, 126453, 31073, 124325, 124058, 125573, 73441, 129581, 140545, 82168, 39697, 124678, 63237, 128288, 68785, 128248, 53710, 69682, 14558, 136719, 127087, 136079, 98719, 13, 715, 128342, 130208, 137961, 125449, 39697, 124179, 137024, 140597, 55334, 73441, 130570, 14558, 127837, 37524, 137355, 127837, 128252, 125100, 138648, 25871, 128248, 127647, 20064, 124966, 142887, 126510, 128953, 128443, 13, 45577, 138023, 50243, 32790, 69682, 25871, 124172, 127288, 77273, 39434, 123890, 20064, 77273, 134259, 74315, 124223, 123860, 125013, 135640, 129745, 68785, 128660, 126502, 125229, 126420, 128098, 124209, 13325, 124072, 33090, 55334, 21360, 126196, 137024, 123961, 128559, 124325, 68785, 128261, 50243, 39697, 124675, 129353, 132450, 143826, 131801, 124072, 124363, 130142, 128252, 125100, 138648, 25871, 128248, 125637, 129152, 142887, 124863, 37524, 123993, 126751, 93153, 124388, 124421, 125011, 13, 138829, 124678, 127837, 27846, 130400, 126543, 17166, 123940, 124552, 123961, 132261, 27846, 58656, 123995, 128617, 68785, 128476, 126214, 73274, 124131, 55057, 77703, 127288, 125572, 23224, 124176, 68785, 128707, 58656, 127837, 27846, 20931, 127552, 68238, 73594, 2236, 198, 4913, 26485, 6112, 788, 330, 31382, 125510, 8532, 128967, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 37524, 133877, 16157, 128248, 138752, 497, 330, 26485, 51354, 788, 4383, 135564, 20064, 497, 330, 31382, 123993, 124917, 142887, 126510, 497, 330, 31382, 127570, 47632, 497, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 31382, 134700, 124058, 125573, 73441, 7914, 330, 26485, 27251, 788, 4383, 14293, 130010, 123980, 131801, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 10465, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 39434, 131377, 12961, 124126, 27490, 132070, 130153, 85153, 125669, 98719, 128707, 32790, 133955, 10465, 330, 31382, 134700, 124058, 125573, 73441, 39434, 125267, 124665, 135590, 125637, 32790, 133955, 37524, 124464, 14558, 91335, 10176, 125006, 124125, 124181, 138751, 14558, 10465, 330, 31382, 123993, 124917, 140597, 55334, 73441, 39434, 64604, 129080, 124476, 126992, 123904, 25871, 128248, 124172, 127288, 10465, 330, 124341, 43635, 80970, 23224, 47632, 124269, 69682, 14558, 39434, 129198, 39434, 127923, 52157, 124232, 73441, 126543, 59842, 125090, 73771, 13325, 1189, 1125, 330, 26485, 11847, 788, 330, 9896, 46979, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 135564, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 127521, 124085, 27846, 124179, 126023, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 124423, 65398, 124220, 5703, 135063, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 123904, 127188, 125572, 124104, 133065, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 136961, 124478, 43635, 124394, 53479, 124811, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 31382, 134700, 124058, 125573, 73441, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 127137, 128586, 143826, 125006, 138391, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 84532, 125520, 220, 16, 19, 134340, 497, 330, 2996, 1819, 788, 330, 3087, 9207, 23439, 73594, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "# story\n",
            "عاد الحديث بقوة في تونس، خلال الأسابيع القليلة الماضية، عن استقلال السلطة القضائية، وعن العدل في تنفيذ قرارات المحاكم، وعن دولة القانون والمؤسسات، وعن المحاكمة العادلة، وذلك على خلفية الجدل القائم بين الهيئة العليا للانتخابات والمحكمة الإدارية، بشأن قرارات هذه الأخيرة التي ضربت بها الهيئة عرض الحائط. \n",
            " اعتقدت النخب التونسية أن الإصلاحات القانونية التي أقدمت عليها حكومات ما بعد الثورة، من خلال دستور 2014، قد باتت أمرًا محسومًا ولا مجال للتراجع عنه. فقد وضع المشرّعون، بعد نقاشات ماراثونية طويلة امتدت لنحو ثلاث سنوات، أسس المحاكمة العادلة وشروطها ومعاييرها الدولية المعروفة. غير أن تعاطي هيئة الانتخابات مع قرار المحكمة الإدارية، أعاد الوضع إلى نقطة الصفر، وأعطى الانطباع بأن البلاد تسير بخطى ثابتة إلى الخلف، بدلًا من العكس. \n",
            " قبلت المحكمة الإدارية طعون ثلاثة مرشحين للانتخابات الرئاسية، وقررت إرجاعهم إلى السباق الانتخابي، ملغية بذلك قرارات الهيئة التي أسقطتهم بدون وجه قانوني وبتعلّات واهية، كما وصف ذلك المرشحون الثلاثة، وكما نص عليه ضمنيًا قرار المحكمة. \n",
            " وفيما توقع الرأي العام في الداخل والخارج، والفاعلون السياسيون، استئناف المرشحين لمكانهم ضمن المشهد الانتخابي كمنافسين جديين للرئيس قيس سعيّد، المنتهية ولايته، بما يجعل لانتخابات السادس من أكتوبر المقبل طعمًا ومذاقًا، جاء قرار هيئة الانتخابات محبطًا للجميع، من خلال الإمعان في إقصاء المرشحين الثلاثة. \n",
            " هذا القرار كان بمثابة بصيص أمل في تحقيق وضع انتخابي جاد يضمن مبدأ تكافؤ الفرص والتنافس النزيه، وسط حالة من التوافق الضمني بين العائلات السياسية على التحشيد خلف مرشح واحد؛ لضمان إحداث التغيير الذي يتطلع إليه كثيرون، حتى أولئك الذين اصطفوا خلف انقلاب 25 يوليوتموز 2021، وكانوا من أكثر المدافعين عنه، والمبررين للممارسات والخطوات التي اتُّخذت لاحقًا، والتي يصفها خصوم الرئيس قيس سعيّد بـالاستبدادية والدكتاتورية. \n",
            " لقد اقتنع أغلب هؤلاء بأنّ التغيير ممكن، بل هو ضروري. \n",
            " قرار هيئة الانتخابات هذا تسبب في سيل عارم من الانتقادات اللاذعة، صدرت عن رجال قانون وشخصيات سياسية وأحزاب ومنظمات، وفعاليات حقوقية في الداخل والخارج. وتم وصفه بـالتعسفي والإقصائي والمنحاز لرئيس الدولة الحالي. بل اتهمت الهيئة بتحولها إلى أداة لدى السلطة التنفيذية، بما أفقدها استقلاليتها، وبالتالي مصداقيتها، ونزع عنها صفة الحياد التي عُرفت بها الهيئة منذ إنشاء أول نسخة منها في العام 2011، بمناسبة أول انتخابات تعددية حقيقية في البلاد، إبّان ثورة 14 ينايركانون الثاني 2011. \n",
            " انتظر المحيط السياسي والشعبي تراجعًا من الهيئة؛ لضمان شفافية الانتخابات ونزاهتها، لكن هذه الأخيرة أصرت على موقفها. وخرج رئيسها، فاروق بوعسكر، ليعلن مجددًا استمرار إقصاء المرشحين الثلاثة عماد الدايمي، ومنذر الزنايدي، وعبد اللطيف المكي. ووجه اتهامًا للمحكمة الإدارية بخرق الإجراءات القانونية، الشيء الذي نفته المحكمة نفيًا قاطعًا، عبر عرض وثائق تؤكد سلامة إجراءاتها وخطواتها وفقًا للقانون والمجلة الجزائية المنظمة لعمل المحكمة ومجالات تدخلها. \n",
            " وفي خطوة متقدمة من هذا الصراع الناشئ، لجأت بعض الأطراف في البلاد إلى مقاضاة هيئة الانتخابات، باعتبارها تعمّدت تجاوز السلطة، ولم تقبل بقرارات الجهة الوحيدة المحكِّمة في العملية الانتخابية، وهي المحكمة الإدارية، التي تعدّ أحكامها باتّة ونهائية، أي غير قابلة للطعن أو الإلغاء، وفق فقهاء القانون والقضاة الإداريين، مثل القاضي الإداري المعروف أحمد صواب، الذي رفع بدوره دعوى قضائية ضد الهيئة، بوصفه مواطنًا ناخبًا، وليس بصفته القضائية. \n",
            " كانت مهمة المحكمة الإدارية التي أُنشئت العام 1972 تنحصر في مجرد البتّ في دعاوى تجاوز السلطة، التي يتم رفعها لإلغاء مقررات إدارية، قبل أن يتم تعديل القوانين المنظمة لها عام 2014، باتجاه إكسابها مزيدًا من الاستقلالية، ومنحها العلوية في قراراتها، خصوصًا في النزاعات الانتخابية، بما يجعل لها الولاية على المسار الانتخابيّ. \n",
            " غير أن هيئة الانتخابات رأت خلاف ذلك تمامًا. فقد مرّغت قرارات المحكمة الإدارية في التراب، وجعلت منها هيكلًا بلا روح، معلنة احتكارها الولاية على الانتخابات ومساراتها المختلفة، من إعلان تاريخها إلى الإعلان عن نتائجها النهائية. \n",
            " تعامل هيئة الانتخابات مع قرارات المحكمة الإدارية يعيد البلاد إلى نقطة الصفر، مما أثار مخاوف حول استقلال القضاء ونزاهة العملية الانتخابية \n",
            " ورغم الجدل الذي لم ينتهِ إلى الآن بين المؤسستين، فإن النتيجة واحدة، وهي إقصاء المرشحين الثلاثة، والإبقاء على الثلاثي المعلن منذ البداية الرئيس قيس سعيّد، وزهير المغزاوي أمين عام حركة الشعب، والعياشي الزمال رئيس حركة عازمون الذي أُدخل السجن موقوفًا؛ بسبب جرائم تدليس التزكيات الشعبية، حسب اتهام السلطة له. \n",
            " ليس هذا وحسب، بل سارعت السلطة التنفيذية إلى نشر قرار الهيئة ضمن الجريدة الرسمية للجمهورية التونسية؛ لقطع الطريق أمام أي أمل في العودة إلى الوراء، كما يردد الرئيس سعيّد دائمًا. \n",
            " بل إن السلطة، مكنت هيئة الانتخابات من شحنة الحبر الانتخابي، والأكياس الآمنة، الخاصة بأوراق الاقتراع، في رسالة مضمونة الوصول، بأن أمر المرشحين الثلاثة الذين أصرت الهيئة على إسقاط ترشحهم للانتخابات الرئاسية قد حُسم بشكل لا رجعة فيه، وأن خيار هيئة الانتخابات كان سليمًا ومنطقيًا، في تقدير السلطة. \n",
            " والحقيقة، ليست هذه المرة الأولى التي يتم فيها رفض تنفيذ قرارات المحكمة الإدارية. فقد سبق لوزارة العدل أن رفضت أو تغاضت عن تنفيذ حكم المحكمة الإدارية بإبطال قرار إعفاء القضاة 49 من أصل 57 قاضيًا، الذي اتُّخذ بموجب أمر رئاسي في يونيوحزيران 2022. \n",
            " لم تعبأ وزارة العدل بوضع هؤلاء القضاة، حتى بعد دخولهم في إضراب وحشيّ عن الطعام استمرّ لعدة أيام، ولم تلتفت إلى قرار المحكمة الإدارية. بل الأدهى من ذلك، أن هؤلاء القضاة ما يزالون حتى اليوم محل ملاحقات قضائية من قبل السلطة، لاتهامهم بشنّ إضراب وتعطيل مرفق إداري عمومي بدون وجه حق. \n",
            " حتى المنظمات الاجتماعية التي تزعم دفاعها عن القانون والعدل بين المواطنين، على غرار الاتحاد العام التونسي للشغل المنظمة النقابية الأعرق في تونس، رفضت الإذعان لقرار المحكمة الإدارية الصادر قبل بضعة أسابيع، لصالح مرصد رقابة لمكافحة الفساد، الذي يتزعمه المرشح لرئاسة الجمهورية، عماد الدايمي. \n",
            " وهذا ما تعاني منه المحكمة الإدارية منذ عقود. إذ إن اللجوء إليها سهل وميسر، لكن الاحتكام إلى قراراتها وأحكامها في فضّ النزاعات، ما يزال ضعيفًا، إن لم نقل منعدمًا. وهذا ما يطرح سؤالًا جوهريًا حول أسباب ودواعي عدم تنفيذ قرارات المحكمة الإدارية، على الرغم من كل الصلاحيات التي مُنحت لها. \n",
            " في دراسة علمية قانونية نُشرت مؤخرًا حول تنفيذ أحكام وقرارات القضاء الإداري في تونس، أشار القاضي الإداري، عماد الغابري، إلى ما أسماها تفاقم ظاهرة عدم تنفيذ أحكام القضاء الإداري، حتى أصبح يُنعت بالقضاء الذي لا تُنفذ أحكامه وقراراته، وهي الجملة التي تتردد في الواقع على جميع الألسن في تونس، كترجمة عملية على هذه اللامبالاة التي تواجه بها قرارات المحكمة الإدارية.. لامبالاة تضع اليوم مستقبل القضاء الإداري على كفّ عِفريت. \n",
            " لم ينتهِ النقاش عند عدم تنفيذ قرارات المحكمة الإدارية، إنما تعدّاه ليشمل مسألة الولاية على المسار الانتخابي، وسط تمسك المحكمة بأحقيتها القانونية على هذا الأمر. لكن هيئة الانتخابات كانت قد سبقت الجميع إلى ذلك منذ البداية، من خلال إعلان ولايتها بالكامل على العملية الانتخابية. \n",
            " فهي المحددة لرزنامة الانتخابات، وهي من تقرر تاريخ يوم الاقتراع، وهي من تشرف على عملية التصويت، ومن تعلن عن نتائجه النهائية. وزادت على ذلك، بأن أعطت لنفسها حق الولاية على الإعلام والمؤسسات الإعلامية، بل حتى على المادة الإعلامية المرشحة للبثّ، وعلى ما يُقال في بعض المنابر الإعلامية، خصوصًا الانتقادات التي توجّه إلى الهيئة. \n",
            " ليس هذا وحسب، بل إن هيئة الانتخابات أعلنت ولايتها على مشاركة المنظمات المختصة في مراقبة الانتخابات، مثل منظمتَي أنا يقظ ومراقبون، واتهمتهما بالفساد المالي، بناءً على ما قالت إنها إشعارات من السلطات الرسمية بحصولهما على تمويل أجنبي. هذا يعني أن الهيئة استحوذت حتى على دور القضاء، المخول وحده بتأكيد أو نفي تهمة الفساد المالي على المنظمتين. \n",
            " هذا النزوع للهيمنة على العملية الانتخابية، واستبعاد المحكمة الإدارية من مجالات اختصاصها المنصوص عليها قانونًا في علاقة بالانتخابات، جعلا العديد من الخبراء وأساتذة القانون يخرجون عن صمتهم، ويعبّرون عن رفضهم ذلك بوضوح. \n",
            " فقد اعتبر الأستاذ كمال بن مسعود، المتخصص في القضاء الإداري، أن المحكمة الإدارية تتمتع بالولاية الكاملة على الانتخابات، خصوصًا في النزاعات الانتخابية والأحكام القضائية الباتّة الصادرة عنها، وهو ما أكده عدد من المختصين في القانون الدستوري، في بيان نُشر الأسبوع المنقضي في عدة منابر إعلامية تونسية وأجنبية. \n",
            " لا يقتصر المشكل على الولاية على الانتخابات، أو على مكانة القضاء الإداري، أو على مجالات تنفيذ قرارات المحكمة الإدارية. فتلك هي الشجرة التي تخفي الغابة، كما يقال. الأمر يتعلق بمشكلة سياسية في العمق، ترتبط بالإرادة السياسية في المحاكمات العادلة، وجعل القضاء هو الفيصل في النزاعات بين السلطة وخصومها، وتحقيق استقلال المؤسسة القضائية، وضمان مبدأ الفصل بين السلطات، وحماية الحقوق المدنية والسياسية، والحريات بجميع تمظهراتها. \n",
            " هذا ما تعكسه المعارك الحقيقية اليوم، التي يبدو أن ملف المحكمة الإدارية ليس سوى جزء من كل، على رأي المناطقة القدماء. \n",
            " إن الأمر يتعلق بنزوع السلطة التنفيذية تاريخيًا وحاضرًا إلى الهيمنة على المؤسسة القضائية بشكل عام. فمنذ نشأة القضاء في تونس في نهاية خمسينيات القرن الماضي، وهو محكوم بلعبة الشد والجذب مع السلطة الحاكمة، التي نزعت عبر التاريخ التونسي الحديث والمعاصر إلى الهيمنة على المرفق القضائي وسلبه استقلاليته. بدءًا بحكم الرئيس الراحل الحبيب بورقيبة، حيث كان يسمى قضاء الزعيم، مرورًا بفترة ح```json\n",
            "{\"story_title\": \"الجدل حول استقلال السلطة القضائية في تونس وتأثيره على الانتخابات\", \"story_keywords\": [\"تونس\", \"السلطة القضائية\", \"الانتخابات\", \"قيس سعيّد\", \"المحكمة الإدارية\"], \"story_summary\": [\"تزايد الحديث عن استقلال السلطة القضائية في تونس.\", \"الهيئة العليا للانتخابات تواجه انتقادات بسبب إقصاء مرشحين.\", \"المحكمة الإدارية تقبل طعون المرشحين وتعيدهم للسباق الانتخابي.\", \"السلطة التنفيذية تُتهم بالهيمنة على القضاء.\", \"استطلاعات الرأي تظهر تراجع شعبية الرئيس سعيّد.\"], \"story_category\": \"politics\", \"story_entities\": [{\"entity_value\": \"تونس\", \"entity_type\": \"location\"}, {\"entity_value\": \"قيس سعيّد\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"فاروق بوعسكر\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عماد الدايمي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"منذر الزنايدي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عبد اللطيف المكي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"المحكمة الإدارية\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الهيئة العليا للانتخابات\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الاتحاد العام التونسي للشغل\", \"entity_type\": \"organization\"}, {\"entity_value\": \"ثورة 14 يناير\", \"entity_type\": \"event\"}]}\n",
            "```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 198, 4913, 26485, 6112, 788, 330, 31382, 125510, 8532, 128967, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 37524, 133877, 16157, 128248, 138752, 497, 330, 26485, 51354, 788, 4383, 135564, 20064, 497, 330, 31382, 123993, 124917, 142887, 126510, 497, 330, 31382, 127570, 47632, 497, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 31382, 134700, 124058, 125573, 73441, 7914, 330, 26485, 27251, 788, 4383, 14293, 130010, 123980, 131801, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 10465, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 39434, 131377, 12961, 124126, 27490, 132070, 130153, 85153, 125669, 98719, 128707, 32790, 133955, 10465, 330, 31382, 134700, 124058, 125573, 73441, 39434, 125267, 124665, 135590, 125637, 32790, 133955, 37524, 124464, 14558, 91335, 10176, 125006, 124125, 124181, 138751, 14558, 10465, 330, 31382, 123993, 124917, 140597, 55334, 73441, 39434, 64604, 129080, 124476, 126992, 123904, 25871, 128248, 124172, 127288, 10465, 330, 124341, 43635, 80970, 23224, 47632, 124269, 69682, 14558, 39434, 129198, 39434, 127923, 52157, 124232, 73441, 126543, 59842, 125090, 73771, 13325, 1189, 1125, 330, 26485, 11847, 788, 330, 9896, 46979, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 135564, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 127521, 124085, 27846, 124179, 126023, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 124423, 65398, 124220, 5703, 135063, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 123904, 127188, 125572, 124104, 133065, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 136961, 124478, 43635, 124394, 53479, 124811, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 31382, 134700, 124058, 125573, 73441, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 127137, 128586, 143826, 125006, 138391, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 84532, 125520, 220, 16, 19, 134340, 497, 330, 2996, 1819, 788, 330, 3087, 9207, 23439, 73594, 151645, 198]\n",
            "labels:\n",
            "```json\n",
            "{\"story_title\": \"الجدل حول استقلال السلطة القضائية في تونس وتأثيره على الانتخابات\", \"story_keywords\": [\"تونس\", \"السلطة القضائية\", \"الانتخابات\", \"قيس سعيّد\", \"المحكمة الإدارية\"], \"story_summary\": [\"تزايد الحديث عن استقلال السلطة القضائية في تونس.\", \"الهيئة العليا للانتخابات تواجه انتقادات بسبب إقصاء مرشحين.\", \"المحكمة الإدارية تقبل طعون المرشحين وتعيدهم للسباق الانتخابي.\", \"السلطة التنفيذية تُتهم بالهيمنة على القضاء.\", \"استطلاعات الرأي تظهر تراجع شعبية الرئيس سعيّد.\"], \"story_category\": \"politics\", \"story_entities\": [{\"entity_value\": \"تونس\", \"entity_type\": \"location\"}, {\"entity_value\": \"قيس سعيّد\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"فاروق بوعسكر\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عماد الدايمي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"منذر الزنايدي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عبد اللطيف المكي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"المحكمة الإدارية\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الهيئة العليا للانتخابات\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الاتحاد العام التونسي للشغل\", \"entity_type\": \"organization\"}, {\"entity_value\": \"ثورة 14 يناير\", \"entity_type\": \"event\"}]}\n",
            "```<|im_end|>\n",
            "\n",
            "[INFO|configuration_utils.py:696] 2025-05-19 09:31:22,168 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:768] 2025-05-19 09:31:22,170 >> Model config Qwen2Config {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|2025-05-19 09:31:22] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 3.09G/3.09G [00:13<00:00, 222MB/s]\n",
            "[INFO|modeling_utils.py:3904] 2025-05-19 09:31:36,951 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors\n",
            "[INFO|modeling_utils.py:1582] 2025-05-19 09:31:37,053 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1140] 2025-05-19 09:31:37,061 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:4888] 2025-05-19 09:31:38,861 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4896] 2025-05-19 09:31:38,861 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 1.74MB/s]\n",
            "[INFO|configuration_utils.py:1095] 2025-05-19 09:31:40,606 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json\n",
            "[INFO|configuration_utils.py:1140] 2025-05-19 09:31:40,606 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_k\": 20,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n",
            "[INFO|2025-05-19 09:31:40] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
            "[INFO|2025-05-19 09:31:40] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-05-19 09:31:40] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
            "[INFO|2025-05-19 09:31:40] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
            "[INFO|2025-05-19 09:31:40] llamafactory.model.model_utils.misc:143 >> Found linear modules: up_proj,v_proj,gate_proj,k_proj,o_proj,down_proj,q_proj\n",
            "[INFO|2025-05-19 09:31:41] llamafactory.model.loader:143 >> trainable params: 73,859,072 || all params: 1,617,573,376 || trainable%: 4.5660\n",
            "[INFO|trainer.py:741] 2025-05-19 09:31:41,682 >> Using auto half precision backend\n",
            "[INFO|trainer.py:2775] 2025-05-19 09:31:41,691 >> Loading model from /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models/checkpoint-500.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:2369] 2025-05-19 09:32:17,781 >> ***** Running training *****\n",
            "[INFO|trainer.py:2370] 2025-05-19 09:32:17,782 >>   Num examples = 550\n",
            "[INFO|trainer.py:2371] 2025-05-19 09:32:17,782 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2372] 2025-05-19 09:32:17,782 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:2375] 2025-05-19 09:32:17,782 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:2376] 2025-05-19 09:32:17,782 >>   Gradient Accumulation steps = 8\n",
            "[INFO|trainer.py:2377] 2025-05-19 09:32:17,782 >>   Total optimization steps = 204\n",
            "[INFO|trainer.py:2378] 2025-05-19 09:32:17,787 >>   Number of trainable parameters = 73,859,072\n",
            "[INFO|trainer.py:2400] 2025-05-19 09:32:17,790 >>   Continuing training from checkpoint, will skip to saved global_step\n",
            "[INFO|trainer.py:2401] 2025-05-19 09:32:17,790 >>   Continuing training from epoch 7\n",
            "[INFO|trainer.py:2402] 2025-05-19 09:32:17,790 >>   Continuing training from global step 500\n",
            "[INFO|trainer.py:2404] 2025-05-19 09:32:17,790 >>   Will skip the first 7 epochs then the first 192 batches in the first epoch.\n",
            "[INFO|integration_utils.py:817] 2025-05-19 09:32:17,796 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshrouk297adel\u001b[0m (\u001b[33mshrouk297adel-national-telecommunication-institute\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/LLaMA-Factory/wandb/run-20250519_093218-eo27ui9t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnews_finetuning_llamafactory\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/shrouk297adel-national-telecommunication-institute/llamafactory\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/shrouk297adel-national-telecommunication-institute/llamafactory/runs/eo27ui9t\u001b[0m\n",
            "  0% 0/204 [00:00<?, ?it/s][INFO|trainer.py:2643] 2025-05-19 09:32:19,530 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1.7483, 'train_samples_per_second': 943.774, 'train_steps_per_second': 116.685, 'train_loss': 0.0, 'epoch': 1.48}\n",
            "  0% 0/204 [00:00<?, ?it/s]\n",
            "[INFO|trainer.py:3910] 2025-05-19 09:32:20,297 >> Saving model checkpoint to /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models\n",
            "[INFO|configuration_utils.py:696] 2025-05-19 09:32:20,742 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:768] 2025-05-19 09:32:20,743 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2491] 2025-05-19 09:32:21,724 >> tokenizer config file saved in /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2500] 2025-05-19 09:32:21,730 >> Special tokens file saved in /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =      1.483\n",
            "  total_flos               = 68052170GF\n",
            "  train_loss               =        0.0\n",
            "  train_runtime            = 0:00:01.74\n",
            "  train_samples_per_second =    943.774\n",
            "  train_steps_per_second   =    116.685\n",
            "Figure saved at: /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models/training_loss.png\n",
            "Figure saved at: /gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models/training_eval_loss.png\n",
            "[WARNING|2025-05-19 09:32:22] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:4226] 2025-05-19 09:32:22,802 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4228] 2025-05-19 09:32:22,802 >>   Num examples = 66\n",
            "[INFO|trainer.py:4231] 2025-05-19 09:32:22,802 >>   Batch size = 1\n",
            "100% 66/66 [03:28<00:00,  3.15s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =      1.483\n",
            "  eval_loss               =     0.3366\n",
            "  eval_runtime            = 0:03:34.72\n",
            "  eval_samples_per_second =      0.307\n",
            "  eval_steps_per_second   =      0.307\n",
            "[INFO|modelcard.py:449] 2025-05-19 09:35:57,547 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "kSBoR-Fh14cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_Id,\n",
        "    device_map='auto',\n",
        "    torch_dtype=torch_dtype\n",
        "\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")"
      ],
      "metadata": {
        "id": "RUhPQP1C4N1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model_id = \"/gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models\"\n",
        "model.load_adapter(finetuned_model_id)"
      ],
      "metadata": {
        "id": "zJfmqePK6HhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response =generate_response(Details_extraction_messages)"
      ],
      "metadata": {
        "id": "JcY5AWcY4204"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_json(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPYzDpip5jgF",
        "outputId": "0d7c00c0-fc4d-479c-b644-983547ce5d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'story_title': 'تأثير العائلة في علاقات الأفراد بالمال',\n",
              " 'story_keywords': ['العائلة',\n",
              "  'علاقات المال',\n",
              "  'التاريخ المالي',\n",
              "  'الأصول',\n",
              "  'التربية'],\n",
              " 'story_summary': ['مجلة فوربس تشير إلى أهمية العائلة في تشكيل العلاقة بالمال.',\n",
              "  'العلاقات المالية تتأثر بمختلف النماذج الماليية مثل الاستكثار، استخدام المال، وإدارة المال.',\n",
              "  'التجارب الأسرية تحدد شخصيات مالية مختلفة لدى الأفراد.',\n",
              "  'الدراسة تقدم أدوات مثل مخطط الجينوم المالي لتقييم التأثيرات السلبية.',\n",
              "  'العائلات التي تعاني من نمط استهلاك مالي مفرط قد تواجه مشكلات نفسية.'],\n",
              " 'story_category': 'Economy',\n",
              " 'story_entity': [{'entity_value': 'فوربس', 'entity_type': 'organization'},\n",
              "  {'entity_value': 'شاين إنيت', 'entity_type': 'person-male'},\n",
              "  {'entity_value': 'رابطة العلاج المالي', 'entity_type': 'organization'},\n",
              "  {'entity_value': 'Money Genogram', 'entity_type': 'product'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=generate_response(translation_messages)"
      ],
      "metadata": {
        "id": "qIThkC5P891j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_json(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTsS0UBX9Ja9",
        "outputId": "7786064c-ee00-48be-ae96-209cf32a92de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation_titl': 'The Role of Family in Financial Relationships',\n",
              " 'translation_content': 'Forbes magazine reported that family plays a central role in shaping individuals\\' financial relationships, influenced by inherited financial behaviors across generations.\\n\\nThis report is based on research conducted by Professor Shane Einthoven on wealth management, explaining that each person has an individual finance profile determined by their interaction with money, which is directly affected by family upbringing and childhood experiences.\\n\\nThe three dimensions of our relationship with money\\nAccording to the study, there are three main dimensions that form our financial relationship:\\n\\nAcquisition (A): Individuals belonging to this dimension tend to view money as a commodity to be accumulated, considering wealth accumulation as a goal itself. The negative aspect of this behavior is the potential for it to lead to a love affair with wealth or vice versa, i.e., complete rejection of wealth accumulation as a source of corruption.\\n\\nUsage (U): These individuals see money as a means for enjoying life, linking its value to its ability to provide enjoyment and comfort. However, some may become addicted to spending, while others turn towards extreme frugality fearing the future.\\n\\nManagement (M): This group views money as a responsibility requiring careful planning. In some cases, it can turn into an obsessive compulsion over managing expenses, negatively impacting personal relationships.\\n\\nHow does family influence our financial relationship?\\nThe report indicates that family experiences play a crucial role in determining \"individual finance\" for each individual, for example, if one parent relies on money as a reward for good behavior, the child later adopts the same pattern in adulthood.\\nTo analyze these influences accurately, the Financial Therapy Association developed a tool called the Money Genome Map (Genogram), used to identify financial patterns within families.\\n\\nThis tool includes:\\n\\nFamily tree drawing.\\nClassification of family members according to the three dimensions of financial relationship (A, U, M).\\nDetermining whether each individual\\'s financial behavior is healthy (+) or unhealthy (-). For instance, if someone grew up in a family where they were accustomed to excessive spending, they may have a strong inclination to adopt the same pattern in their adult life, or the opposite, turning excessively strict as a self-defense mechanism.'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cost Estimation for the model after fintuned\n",
        "- Test model speed on generation"
      ],
      "metadata": {
        "id": "wNBlj2K49yud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "fake=Faker('ar')\n",
        "fake.text(max_nb_chars=random.randint(150,200))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G1DbRTXa9WY1",
        "outputId": "f84edb94-a41c-44f6-c5b8-239f5081dcc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'وباستثناء إختار سابق بكلا. يرتبط أسابيع يبق الأراضي. فشكّل السيء معاملة. تونس دارت لبولندا مشروط كرسي الآخر.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "from  datetime import datetime\n",
        "fake=Faker('ar')\n",
        "\n",
        "input_tokens= 0\n",
        "output_tokens =0\n",
        "start_time =datetime.now()\n",
        "\n",
        "for i in tqdm(range(30)):\n",
        "  prompt = fake.text(max_nb_chars=random.randint(150,200))\n",
        "\n",
        "  messages=[\n",
        "  {\n",
        "      'role':'user',\n",
        "      'content':prompt\n",
        "  }\n",
        "  ]\n",
        "\n",
        "  response =generate_response(messages)\n",
        "\n",
        "  input_tokens +=len(tokenizer.apply_chat_template(messages))\n",
        "  output_tokens +=len(tokenizer.encode(response))\n",
        "\n",
        "\n",
        "total_time =(datetime.now()-start_time).total_seconds()\n",
        "\n",
        "print(f\"Total Time:{total_time} seconds\")\n",
        "print(f\"Input Tokens:{input_tokens}\")\n",
        "print(f\"Output Tokens:{output_tokens}\")\n",
        "print(f\"Total Tokens:{input_tokens+output_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "77ed059fa8bc4f3bbbcd46800deedfa0",
            "2ab3164455464ca993629f412018f675",
            "93b7e73eca514ee7b279ebf3138637fc",
            "463d393e948b470ba4d8752c5a01170a",
            "94207f7222df4dc48726f9519c61cbf1",
            "d31904c9be6e4979a24b29ffb7f1b40d",
            "ce9df17aa51147999356fdbc0a562806",
            "4c3ffee202334180a7f3b348b151bd58",
            "f910b19e3b77490abd3c3b29dc2ba8f5",
            "c5ca6998cf244efeb57fc0d495ae31e0",
            "f91f440b4a68445197baac86c3b42fa3"
          ]
        },
        "id": "9arnhEHsAjQF",
        "outputId": "e628ed7e-b42c-47f9-8d81-2564dd573545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77ed059fa8bc4f3bbbcd46800deedfa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Time:613.942767 seconds\n",
            "Input Tokens:2395\n",
            "Output Tokens:11245\n",
            "Total Tokens:13640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "13640 /613  # generate 22 token per second"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kbAMsKIHak3",
        "outputId": "00775328-7434-465d-d4a4-2a2e9b01713d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.251223491027734"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## vLLM"
      ],
      "metadata": {
        "id": "7sdx1eqjT5WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Id ='Qwen/Qwen2.5-1.5B-Instruct'\n",
        "lora_model_Id =\"/gdrive/MyDrive/Fine-Tuning/Datasets/LLaMaFactory-Finetuning-data/models\"\n",
        "\n",
        "!nohup vllm serve \"{base_model_Id}\" --dtype=half --gpu-memory-utilization 0.8 --max-lora-rank 64 --enable-lora --lora-modules news-lora=\"{lora_model_Id}\" &"
      ],
      "metadata": {
        "id": "5QiIXTP3PFsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 30 nohup.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNbaUZdDvtE3",
        "outputId": "bb2b86c0-7396-40fa-c544-a642326feec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tail: cannot open 'nohup.out' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "xpPShNEg10gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "prompt =tokenizer.apply_chat_template(translation_messages,\n",
        "                                      tokenize=False,\n",
        "                                      add_generation_prompt=True)\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "QaHSOVwnwsUD",
        "outputId": "24d71103-0438-4cf0-bc1f-770bc6393c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|im_start|>system\\nyou are a professional translator\\ntranslate story for the target language\\ndo not generate any introduction or conclusion\\nfollow the provided schema to generate json<|im_end|>\\n<|im_start|>user\\n## Story:\\nذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\\n حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\\n\\nالتقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\\nالرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\\n تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\\n\\n الأبعاد الثلاثة للعلاقة بالمال\\nبحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\\n\\nالاكتساب (A): يميل الأفراد الذين ينتمون لهذا\\n البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\\nفي تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\\n النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\\n أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\\n\\nالاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\\nالمتعة والراحة. ومع ذلك، قد يصبح\\nالبعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\\n\\nالإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\\n قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\\n\\n كيف تؤثر العائلة على علاقتنا بالمال؟\\nيشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\\n \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\\nكمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\\n\\nلتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\\n(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\\nوهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\\n\\nتتضمن هذه الأداة:\\n\\nرسم شجرة عائلية.\\nتصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\\nتحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\\nعلى سبيل المثال، إذا نشأ شخص في عائلة\\nاعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\\n أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\\n\\nthe pydantic details:\\n{\"properties\": {\"translation_titl\": {\"Description\": \"genrate title for the translated story\", \"minLength\": 5, \"title\": \"Translation Titl\", \"type\": \"string\"}, \"translation_content\": {\"Desciption\": \"Tranlated Content for the new Story \", \"min_lenght\": 5, \"title\": \"Translation Content\", \"type\": \"string\"}}, \"required\": [\"translation_titl\", \"translation_content\"], \"title\": \"TranslatedStory\", \"type\": \"object\"}\\n\\nTarget language:\\nEnglish<|im_end|>\\n<|im_start|>assistant\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vllm_model_id='news-lora'\n",
        "\n",
        "llm_response=requests.post(\"http://localhost:8000/v1/completions\",json={\n",
        "    'model':vllm_model_id,\n",
        "    'prompt':prompt,\n",
        "    'max_tokens':1000,\n",
        "    'temperature':0.3\n",
        "})\n",
        "\n",
        "llm_response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "HDh458Y92Y3_",
        "outputId": "74e99d21-f01f-46bd-9b88-7bad284dee0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"id\":\"cmpl-bae13276e7974f1e956111353610ca80\",\"object\":\"text_completion\",\"created\":1747832275,\"model\":\"news-lora\",\"choices\":[{\"index\":0,\"text\":\"```json\\\\n{\\\\\"translation_titl\\\\\": \\\\\"The Role of Family in Financial Relationships\\\\\", \\\\\"translation_content\\\\\": \\\\\"Forbes magazine reported that the family plays a crucial role in shaping individuals\\' financial relationships, as these relationships are influenced by inherited financial behaviors across generations.\\\\\\\\n\\\\\\\\nThe report, based on research by Professor Shane Enye on financial well-being, explains that each person has a \\\\\"financial personality\\\\\" determined by their interaction with money, which is directly affected by family upbringing and childhood experiences.\\\\\\\\n\\\\\\\\nThe three dimensions of the financial relationship\\\\\\\\nAccording to the study, there are three main dimensions that form our financial relationship:\\\\\\\\n\\\\\\\\nA: Individuals belonging to this dimension tend to view money as a commodity to be accumulated, seeing wealth accumulation as a goal in itself. This aspect can lead to a tendency towards a love for wealth or the opposite, i.e., complete rejection of wealth accumulation as a means of corruption.\\\\\\\\n\\\\\\\\nU: These individuals view money as a tool for enjoying life, linking its value to its ability to provide enjoyment and comfort. However, some may become addicted to spending, while others may turn to extreme frugality in fear of the future.\\\\\\\\n\\\\\\\\nM: Individuals of this type consider money as a responsibility that requires careful planning. In some cases, this may turn into an obsessive concern with managing expenses, which negatively affects personal relationships.\\\\\\\\n\\\\\\\\nHow does family influence our financial relationship?\\\\\\\\nThe report indicates that family experiences play a crucial role in determining the \\\\\"financial personality\\\\\" of each individual, for example, if one parent relies on money as a reward for good behavior, the child may later adopt the same pattern in their adult life.\\\\\\\\n\\\\\\\\nTo analyze these influences accurately, the Financial Therapy Association developed a tool called the Money Genogram (Genogram of Money), which is used to identify financial patterns within the family.\\\\\\\\n\\\\\\\\nThis tool includes:\\\\\\\\n\\\\\\\\nA family tree diagram.\\\\\\\\nClassification of family members according to the three dimensions of the financial relationship (A, U, M).\\\\\\\\nDetermining whether the financial behavior of each individual is healthy (+) or unhealthy (-).\\\\\\\\nFor example, if a person grew up in a family that encouraged excessive spending, they may have a strong tendency to adopt the same pattern, or the opposite, where they become excessively frugal as a psychological response.\\\\\"}\\\\n```\",\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null,\"prompt_logprobs\":null}],\"usage\":{\"prompt_tokens\":845,\"total_tokens\":1316,\"completion_tokens\":471,\"prompt_tokens_details\":null}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuzCHzfN7Mlp",
        "outputId": "4304efa3-d118-4c21-b868-9aa1132dad2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'cmpl-bae13276e7974f1e956111353610ca80',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1747832275,\n",
              " 'model': 'news-lora',\n",
              " 'choices': [{'index': 0,\n",
              "   'text': '```json\\n{\"translation_titl\": \"The Role of Family in Financial Relationships\", \"translation_content\": \"Forbes magazine reported that the family plays a crucial role in shaping individuals\\' financial relationships, as these relationships are influenced by inherited financial behaviors across generations.\\\\n\\\\nThe report, based on research by Professor Shane Enye on financial well-being, explains that each person has a \"financial personality\" determined by their interaction with money, which is directly affected by family upbringing and childhood experiences.\\\\n\\\\nThe three dimensions of the financial relationship\\\\nAccording to the study, there are three main dimensions that form our financial relationship:\\\\n\\\\nA: Individuals belonging to this dimension tend to view money as a commodity to be accumulated, seeing wealth accumulation as a goal in itself. This aspect can lead to a tendency towards a love for wealth or the opposite, i.e., complete rejection of wealth accumulation as a means of corruption.\\\\n\\\\nU: These individuals view money as a tool for enjoying life, linking its value to its ability to provide enjoyment and comfort. However, some may become addicted to spending, while others may turn to extreme frugality in fear of the future.\\\\n\\\\nM: Individuals of this type consider money as a responsibility that requires careful planning. In some cases, this may turn into an obsessive concern with managing expenses, which negatively affects personal relationships.\\\\n\\\\nHow does family influence our financial relationship?\\\\nThe report indicates that family experiences play a crucial role in determining the \"financial personality\" of each individual, for example, if one parent relies on money as a reward for good behavior, the child may later adopt the same pattern in their adult life.\\\\n\\\\nTo analyze these influences accurately, the Financial Therapy Association developed a tool called the Money Genogram (Genogram of Money), which is used to identify financial patterns within the family.\\\\n\\\\nThis tool includes:\\\\n\\\\nA family tree diagram.\\\\nClassification of family members according to the three dimensions of the financial relationship (A, U, M).\\\\nDetermining whether the financial behavior of each individual is healthy (+) or unhealthy (-).\\\\nFor example, if a person grew up in a family that encouraged excessive spending, they may have a strong tendency to adopt the same pattern, or the opposite, where they become excessively frugal as a psychological response.\"}\\n```',\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'stop',\n",
              "   'stop_reason': None,\n",
              "   'prompt_logprobs': None}],\n",
              " 'usage': {'prompt_tokens': 845,\n",
              "  'total_tokens': 1316,\n",
              "  'completion_tokens': 471,\n",
              "  'prompt_tokens_details': None}}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Testing"
      ],
      "metadata": {
        "id": "wKkJqcdN5iCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile locust.py\n",
        "import random\n",
        "import json\n",
        "from locust import HttpUser,task,between,constant\n",
        "from transformers import AutoTokenizer\n",
        "from faker import Faker\n",
        "\n",
        "faker=Faker('ar')\n",
        "\n",
        "class completionLoadTest(HttpUser):\n",
        "  wait_time =between(1,3)\n",
        "\n",
        "  @task\n",
        "  def post_completeion(self):\n",
        "    model_id='news-lora'\n",
        "    prompt =faker.text(max_nb_chars=random.randint(150,200))\n",
        "\n",
        "    message={'model':model_id,\n",
        "    'prompt':prompt,\n",
        "    'max_tokens':512,\n",
        "    'temperature':0.3\n",
        "    }\n",
        "\n",
        "    llm_response=self.client.post(\"/v1/completions\",json= message)\n",
        "\n",
        "    if llm_response.status_code ==200:\n",
        "      with open('./vllm_token_.text','a') as dest:\n",
        "        dest.write(json.dumps({\n",
        "            \"prompt\":prompt,\n",
        "            'resposne':llm_response.json()[\"choices\"][0][\"text\"]\n",
        "        },ensure_ascii=False )+\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX7knBPz5jqQ",
        "outputId": "9b078cda-2641-44f9-ac83-8773a84dbc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting locust.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!locust --headless -f locust.py --host=http://localhost:8000 -u 20 -r 1 -t \"60s\" --html=locust_result.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuuoX_Ql8iXV",
        "outputId": "4df78e2c-68ea-47c9-8767-35030c4d94fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-05-21 14:01:57,709] befdd81360ad/INFO/locust.main: Starting Locust 2.37.4\n",
            "[2025-05-21 14:01:57,726] befdd81360ad/INFO/locust.main: Run time limit set to 60 seconds\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
            "\n",
            "[2025-05-21 14:01:57,756] befdd81360ad/INFO/locust.runners: Ramping to 20 users at a rate of 1.00 per second\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions       1     0(0.00%) |    801     801     801    801 |    0.00        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated       1     0(0.00%) |    801     801     801    801 |    0.00        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions       3     0(0.00%) |    421     145     801    320 |    0.50        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated       3     0(0.00%) |    421     145     801    320 |    0.50        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions       3     0(0.00%) |    421     145     801    320 |    0.50        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated       3     0(0.00%) |    421     145     801    320 |    0.50        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions       6     0(0.00%) |    371     103     801    310 |    0.50        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated       6     0(0.00%) |    371     103     801    310 |    0.50        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions       7     0(0.00%) |    346     103     801    310 |    0.43        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated       7     0(0.00%) |    346     103     801    310 |    0.43        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions       9     0(0.00%) |    299     103     801    200 |    0.70        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated       9     0(0.00%) |    299     103     801    200 |    0.70        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      13     0(0.00%) |    252     103     801    150 |    0.70        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      13     0(0.00%) |    252     103     801    150 |    0.70        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      14     0(0.00%) |    249     103     801    150 |    0.90        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      14     0(0.00%) |    249     103     801    150 |    0.90        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      15     0(0.00%) |   1295     103   15944    180 |    1.00        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      15     0(0.00%) |   1295     103   15944    180 |    1.00        0.00\n",
            "\n",
            "[2025-05-21 14:02:16,779] befdd81360ad/INFO/locust.runners: All users spawned: {\"completionLoadTest\": 20} (20 total users)\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      18     0(0.00%) |   1113     103   15944    190 |    1.10        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      18     0(0.00%) |   1113     103   15944    190 |    1.10        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      20     0(0.00%) |   2823     103   18371    200 |    1.10        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      20     0(0.00%) |   2823     103   18371    200 |    1.10        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      21     0(0.00%) |   3572     103   18544    200 |    1.10        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      21     0(0.00%) |   3572     103   18544    200 |    1.10        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      25     0(0.00%) |   4567     103   19681    200 |    1.00        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      25     0(0.00%) |   4567     103   19681    200 |    1.00        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      27     0(0.00%) |   4931     103   19681    200 |    0.90        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      27     0(0.00%) |   4931     103   19681    200 |    0.90        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      33     0(0.00%) |   5813     103   19681    200 |    1.20        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      33     0(0.00%) |   5813     103   19681    200 |    1.20        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      33     0(0.00%) |   5813     103   19681    200 |    1.20        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      33     0(0.00%) |   5813     103   19681    200 |    1.20        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      36     0(0.00%) |   5913     103   20694    200 |    1.40        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      36     0(0.00%) |   5913     103   20694    200 |    1.40        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      39     0(0.00%) |   6535     103   20915    210 |    1.40        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      39     0(0.00%) |   6535     103   20915    210 |    1.40        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      42     0(0.00%) |   7572     103   21143    210 |    1.40        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      42     0(0.00%) |   7572     103   21143    210 |    1.40        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      46     0(0.00%) |   7844     103   21280    210 |    1.50        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      46     0(0.00%) |   7844     103   21280    210 |    1.50        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      47     0(0.00%) |   8129     103   21280    210 |    1.50        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      47     0(0.00%) |   8129     103   21280    210 |    1.50        0.00\n",
            "\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      49     0(0.00%) |   8661     103   21280    310 |    1.30        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      49     0(0.00%) |   8661     103   21280    310 |    1.30        0.00\n",
            "\n",
            "[2025-05-21 14:02:42,484] befdd81360ad/INFO/locust.main: --run-time limit reached, shutting down\n",
            "[2025-05-21 14:02:42,735] befdd81360ad/INFO/locust.main: writing html report to file: locust_result.html\n",
            "[2025-05-21 14:02:42,739] befdd81360ad/INFO/locust.main: Shutting down (exit code 0)\n",
            "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "POST     /v1/completions      49     0(0.00%) |   8661     103   21280    310 |    1.15        0.00\n",
            "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
            "         Aggregated      49     0(0.00%) |   8661     103   21280    310 |    1.15        0.00\n",
            "\n",
            "Response time percentiles (approximated)\n",
            "Type     Name      50%    66%    75%    80%    90%    95%    98%    99%  99.9% 99.99%   100% # reqs\n",
            "--------||--------|------|------|------|------|------|------|------|------|------|------|------\n",
            "POST     /v1/completions      310  19000  20000  21000  21000  21000  21000  21000  21000  21000  21000     49\n",
            "--------||--------|------|------|------|------|------|------|------|------|------|------|------\n",
            "         Aggregated      310  19000  20000  21000  21000  21000  21000  21000  21000  21000  21000     49\n",
            "\n"
          ]
        }
      ]
    }
  ]
}